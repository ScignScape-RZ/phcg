`section.Conclusion`
`p.
In the last section, I outlined a theory 
of `i.annotative fusion` which generalizes 
(and migrates from natural to formal languages) 
Link Grammar to fields like type theory, 
programming language design, and (suitably 
extended) lambda calculii.  The crux of this 
extension is taking a formulation of 
hypergraph transforms %-- where hypergraph 
edge-pairs map to annotatd hypredges %-- and 
then reading `q.annotations` as general computational 
structures, where an `q.annotative fusion` represents 
the executive machinery requisite to implement 
(sequential or concurrent) calls between 
procedures.  As with link grammar, which recognizes 
many link types (or in these terms many 
premises for tail-to-head pre-annotation fusion), 
this rough picture allows many different kinds 
of inter-procedure calls, coding paradigms, 
and functional side-effects to be represented.  
For example, Object-Oriented code exhibits a 
particular kind of inter-procedure connection, 
subject to special semantic and 
syntactic conventions (notably the object 
value in an expression is bound to a `q.this` 
or `q.self` symbol in the callee code).  In 
languages like `Cpp; and Java, Object-Oriented 
expressions are notated by placing the object symbol 
(or nested expression) before a `q.dot` token and 
then a function name.  The `q.dot` then signals 
the presence of two connectors, one to its left 
that marks a symbol or expression as an object 
(and thus connected to a `q.this` symbol in callee code) 
and one to its right that marks a symbol 
as a function name (and so bound to whichever  
procedure uniquely resolves the procdure-call 
at runtime given the runtime type of 
the arguments).  
`p`

`p.
As this example shows, one could write a formal 
grammar for Object Oriented languages 
%-- e.g. for a valid expression using an 
object and a valid signature of a function that takes an 
object as its `q.this` argument %-- with syntax-rule 
representations essentially identical to Link Grammars 
for Natural Language.  In place of link-types 
like verb-subject, verb-object, antecedent-pronoun, 
etc., this `i.programming` language grammar would 
have connections like object-expressions and 
object-symbols to `q.this` tokens, thrown 
exception-exprssions to symbols declared in 
`q.catch blocks`/, and so on.  Expanding this 
idea, we can say that modern programming languages 
have multiple form of inter-procedure exchange of 
values, and that for each such alternative 
there is a distinct link-type and a distinct pair 
of `q.connectors` (in established Link 
Grammar terminology) or `q.pre-annotations` 
modeling how values get passed between procdures 
insofar as that communicative protocol is in effect.  
Object-Oriented code uses one protocol for objects, 
a different protocol (essentially the classical 
Lambda Calculus) for other functional arguments, 
and a third protocol for throwing and catching 
exceptions.  In the context of this paper, 
these protocols correspond with specific 
compatibilities between pre-annotations and 
specific regimes for annotative fusion.  
Within each experession/signature match, there 
are in general multiple `q.annotative fusion 
regimes` which must all be properly provisioned 
by the desired procdure-call for the fusion 
to be acceptable.  The values subject to any 
particular regime I then collectively 
call a `i.channel`/, and the rules for 
validating fusions I refer to as a `q.Channel 
Algebra`/.  Type declarations on procedures are 
then enriched with the added structure of 
multiple `q.annotative fusion regimes` 
(which can also be called `q.channel prototypes`/, 
or `q.proto-channels`/) along with the 
distinction between expression-pre-annotative and 
expression-pre-annotative types I mentioned earlier.  
These added structures add levels of dtail 
to the basic notion of `q.functional types` in 
the Typed Lambda Calculus, and we can define type 
systems that are closed over simpler functional 
type systems with respect to annotative-fusion,  
annotative-partiality, and proto-channel operators.  
In Neustein19 I describe these enriched theoris 
as `q.Channelized Type Systems` and give a more 
expansive outline and explanation of their 
formal properties.  For the moment, I will just 
claim for sake of discussion that `q.Channelized` 
type theory according to these criteria is a 
reasonable extension to clasical type theory and 
that the published software represents a concrete 
implementation of a prototype formal language 
whose type system is Channelized in this sense. 
`p`

`p.
Here I openly acknowledge that I am not 
providing a rigorous mathematical exposition of 
these Channelized Type Systems, analogous to 
how other extensions would be presented 
in the type-theory community proper.  This 
is partly be personal choice: I am both 
more interested in and more capable of 
examining forms of type theory via their 
concretization in implemented programming 
languages, rather than their mathematical 
exposition in `q.abstract` programming languages.  
It is certainly possible to formulate formal 
languages as mathematical constructs, using 
theorems as de facto guarantees of their behavior.  
Such hypothetical languages are still not 
actually implemented, however.  Provable 
claims about programming languages are importamt, 
but also valuable are specific implementations 
of languages %-- i.e., software that reads source-code 
files conformant to the language grammar and 
executes operations described by that code %-- 
partly because the code realizing the language 
itself then becomes a concrete artifact 
which can be studied and analyzed in turn.
`p.

`p`
Concrete language implementations are 
therefore an alternative framework for 
developing type theory, separate from purely 
mathematical type theories and from the 
kinds of type systems central to mathematical 
foundations research (e.g., Homotopy Type Thory).  
I'll refer to type theory in the former 
sense as `i.experimental`/, in comparison to 
`q.logico-mathematical` type theories, on the basis 
that claims about the type systems of concrete 
programming languages are often defended by 
appeal to empirical observations about 
program-behavior rather than formal proofs.  
`p`

`p.
I have concluded this paper with a brief reference to 
a `q.Channelized Type Theory`/, which I turned I arived 
at in several phases, from Phenomenology to Cognitive 
Grammar to Link Grammar to Annotated Directed Hypergraphs.  
As with any juxtaposition of philosophical/speculative 
thories and formal/technical ones, claims of 
inter-disciplinary unification (or even overlap) need to 
be cautious and provisional.  It certainly is not 
self-vident that Channelized Type Theory (or Link Grammar 
and Dircted Hypergraphs, or Semantic Web 
Ontologies and Dircted Labeled Graphs) represents 
an adequate or relevant formalization of 
phenomenoligical structures.  To the degree that 
Channelized Type Theory (by analogy to Semantic Web 
paradigms) can be retroactivly interesting to 
Phenomenology at a systematizing or 
intuition-honing level, the resonances between the two 
need to be dilated from well-established theortical 
overlaps (like Phenomenology to Cognitive Grammar), 
tracing a pivot to increasingly formal and/or 
technological structures (as with formalizing 
Cognitive Grammar via Link Grammar and then generalizing 
Link Grammar to formal languages and type theories).  
This paper has been able to present only a few 
examples tieing the phenomenologuical side of this 
progression to the technological side at 
each step along the way.  
`p`

`p.
But without presuming that the mutual relevance between 
Channelized Type Theory and Phenomenology has been 
demonstrated here in anything but skecthy detail, we 
can still consider the meta-philosophical situation 
if such a connction can be made even provisionally.  
As I have proposed, Channelized Type Theory (at least 
the way I have developed it) is `q.experimental` rather 
than rigorously logico-mathematical; as a result, 
a potential formaliztion for some phenomenological 
structures is being presented as a technological 
and esxperimental or empirical artifact rather than 
an abstract mathematical system.  My interest 
in formal models for Phenomenology is inspired by 
the `q.Naturaliing Phenomenology` project and 
particularly by Jean Petitot's formalizing studies 
(alongside David Woodruff Smith's metaphysical 
analyses which, I think, provide a persuasive 
philosophical grounding for Petitot's `q.eidetic` 
scientization).  However, Petitot's interdisciplinary 
orientation is centered on identifying 
mathematical structures (like sheaf mereology) which 
seem to replicate some of the cognitive 
patterning of perceptual and situational 
experience; in short it is formalization via 
mathematical spaces.  As I intimated when contrasting 
Petitot with Barry Smith, the former's strategy 
is still a departure from `q.logical` formalizations 
%-- sheaves are Categorical phenomena rather than 
set-thoretic ones, so sheaf theories are not 
reductively conflated to logical systems 
(though like any Category sheaves `q.have` a 
logic in some sense).  Ptitot's analyses, 
in short, are formalizations of certain phenemenological 
gestalts via mathematical categories rather than via 
the formulation of logical systems that would 
purport to simulate phenemenological structures via 
axioms or syllogisms (again as a counter-example 
I would cite Kit Fine's mereology based on 
Husserl's `i.Logical Investigations`/).
`p`

`p.
But relative to Petitot's mathematical 
`p`

`p.

`p`

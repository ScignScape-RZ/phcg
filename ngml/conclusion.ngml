`section.Conclusion`
`p.
In the last section, I outlined a theory 
of `i.annotative fusion` which generalizes 
(and migrates from natural to formal languages) 
Link Grammar to fields like type theory, 
programming language design, and (suitably 
extended) lambda calculii.  The crux of this 
extension is taking a formulation of 
hypergraph transforms %-- where hypergraph 
edge-pairs map to annotatd hypredges %-- and 
then reading `q.annotations` as general computational 
structures, where an `q.annotative fusion` represents 
the executive machinery requisite to implement 
(sequential or concurrent) calls between 
procedures.  As with link grammar, which recognizes 
many link types (or in these terms many 
premises for tail-to-head pre-annotation fusion), 
this rough picture allows many different kinds 
of inter-procedure calls, coding paradigms, 
and functional side-effects to be represented.  
For example, Object-Oriented code exhibits a 
particular kind of inter-procedure connection, 
subject to special semantic and 
syntactic conventions (notably the object 
value in an expression is bound to a `q.this` 
or `q.self` symbol in the callee code).  In 
languages like `Cpp; and Java, Object-Oriented 
expressions are notated by placing the object symbol 
(or nested expression) before a `q.dot` token and 
then a function name.  The `q.dot` then signals 
the presence of two connectors, one to its left 
that marks a symbol or expression as an object 
(and thus connected to a `q.this` symbol in callee code) 
and one to its right that marks a symbol 
as a function name (and so bound to whichever  
procedure uniquely resolves the procdure-call 
at runtime given the runtime type of 
the arguments).  
`p`

`p.
As this example shows, one could write a formal 
grammar for Object Oriented languages 
%-- e.g. for a valid expression using an 
object and a valid signature of a function that takes an 
object as its `q.this` argument %-- with syntax-rule 
representations essentially identical to Link Grammars 
for Natural Language.  In place of link-types 
like verb-subject, verb-object, antecedent-pronoun, 
etc., this `i.programming` language grammar would 
have connections like object-expressions and 
object-symbols to `q.this` tokens, thrown 
exception-exprssions to symbols declared in 
`q.catch blocks`/, and so on.  Expanding this 
idea, we can say that modern programming languages 
have multiple form of inter-procedure exchange of 
values, and that for each such alternative 
there is a distinct link-type and a distinct pair 
of `q.connectors` (in established Link 
Grammar terminology) or `q.pre-annotations` 
modeling how values get passed between procdures 
insofar as that communicative protocol is in effect.  
Object-Oriented code uses one protocol for objects, 
a different protocol (essentially the classical 
Lambda Calculus) for other functional arguments, 
and a third protocol for throwing and catching 
exceptions.  In the context of this paper, 
these protocols correspond with specific 
compatibilities between pre-annotations and 
specific regimes for annotative fusion.  
Within each experession/signature match, there 
are in general multiple `q.annotative fusion 
regimes` which must all be properly provisioned 
by the desired procdure-call for the fusion 
to be acceptable.  The values subject to any 
particular regime I then collectively 
call a `i.channel`/, and the rules for 
validating fusions I refer to as a `q.Channel 
Algebra`/.  Type declarations on procedures are 
then enriched with the added structure of 
multiple `q.annotative fusion regimes` 
(which can also be called `q.channel prototypes`/, 
or `q.proto-channels`/) along with the 
distinction between expression-pre-annotation and 
signature-pre-annotation types I mentioned earlier.  
These added structures add levels of detail 
to the basic notion of `q.functional types` in 
the Typed Lambda Calculus, and we can define type 
systems that are closed over simpler functional 
type systems with respect to annotative-fusion,  
annotative-partiality, and proto-channel operators.  
In Neustein19 I describe these enriched theoris 
as `q.Channelized Type Systems` and give a more 
expansive outline and explanation of their 
formal properties.  For the moment, I will just 
claim for sake of discussion that `q.Channelized` 
type theory according to these criteria is a 
reasonable extension to clasical type theory and 
that the published software represents a concrete 
implementation of a prototype formal language 
whose type system is Channelized in this sense. 
`p`

`p.
Here I openly acknowledge that I am not 
providing a rigorous mathematical exposition of 
these Channelized Type Systems, analogous to 
how other extensions would be presented 
in the type-theory community proper.  This 
is partly be personal choice: I am both 
more interested in and more capable of 
examining forms of type theory via their 
concretization in implemented programming 
languages, rather than their mathematical 
exposition in `q.abstract` programming languages.  
It is certainly possible to formulate formal 
languages as mathematical constructs, using 
theorems as de facto guarantees of their behavior.  
Such hypothetical languages are still not 
actually implemented, however.  Provable 
claims about programming languages are importamt, 
but also valuable are specific implementations 
of languages %-- i.e., software that reads source-code 
files conformant to the language grammar and 
executes operations described by that code %-- 
partly because the code realizing the language 
itself then becomes a concrete artifact 
which can be studied and analyzed in turn.
`p.

`p`
Concrete language implementations are 
therefore an alternative framework for 
developing type theory, separate from purely 
mathematical type theories and from the 
kinds of type systems central to mathematical 
foundations research (e.g., Homotopy Type Thory).  
I'll refer to type theory in the former 
sense as `i.experimental`/, in comparison to 
`q.logico-mathematical` type theories, on the basis 
that claims about the type systems of concrete 
programming languages are often defended by 
appeal to empirical observations about 
program-behavior rather than formal proofs.  
`p`

`p.
I have concluded this paper with a brief reference to 
a `q.Channelized Type Theory`/, which I turned I arived 
at in several phases, from phenomenology to Cognitive 
Grammar to Link Grammar to Annotated Directed Hypergraphs.  
As with any juxtaposition of philosophical/speculative 
thories and formal/technical ones, claims of 
inter-disciplinary unification (or even overlap) need to 
be cautious and provisional.  It certainly is not 
self-vident that Channelized Type Theory (or Link Grammar 
and Dircted Hypergraphs, or Semantic Web 
Ontologies and Dircted Labeled Graphs) represents 
an adequate or relevant formalization of 
phenomenoligical structures.  To the degree that 
Channelized Type Theory (by analogy to Semantic Web 
paradigms) can be retroactivly interesting to 
phenomenology at a systematizing or 
intuition-honing level, the resonances between the two 
need to be dilated from well-established theortical 
overlaps (like phenomenology to Cognitive Grammar), 
tracing a pivot to increasingly formal and/or 
technological structures (as with formalizing 
Cognitive Grammar via Link Grammar and then generalizing 
Link Grammar to formal languages and type theories).  
This paper has been able to present only a few 
examples tieing the phenomenologuical side of this 
progression to the technological side at 
each step along the way.  
`p`

`p.
But without presuming that the mutual relevance between 
Channelized Type Theory and phenomenology has been 
demonstrated here in anything but skecthy detail, we 
can still consider the meta-philosophical situation 
if such a connction can be made even provisionally.  
As I have proposed, Channelized Type Theory (at least 
the way I have developed it) is `q.experimental` rather 
than rigorously logico-mathematical; as a result, 
a potential formaliztion for some phenomenological 
structures is being presented as a technological 
and esxperimental or empirical artifact rather than 
an abstract mathematical system.  My interest 
in formal models for phenomenology is inspired by 
the `q.Naturaliing phenomenology` project and 
particularly by Jean Petitot's formalizing studies 
(alongside David Woodruff Smith's metaphysical 
analyses which, I think, provide a persuasive 
philosophical grounding for Petitot's `q.eidetic` 
scientization).  However, Petitot's interdisciplinary 
orientation is centered on identifying 
mathematical structures (like sheaf mereology) which 
seem to replicate some of the cognitive 
patterning of perceptual and situational 
experience; in short it is formalization via 
mathematical spaces.  As I intimated when contrasting 
Petitot with Barry Smith, the former's strategy 
is still a departure from `q.logical` formalizations 
%-- sheaves are Categorical phenomena rather than 
set-thoretic ones, so sheaf theories are not 
reductively conflated to logical systems 
(though like any Category sheaves `q.have` a 
logic in some sense).  Ptitot's analyses, 
in short, are formalizations of certain phenemenological 
gestalts via mathematical categories rather than via 
the formulation of logical systems that would 
purport to simulate phenemenological structures via 
axioms or syllogisms (again as a counter-example 
I would cite Kit Fine's mereology based on 
Husserl's `i.Logical Investigations`/).
`p`

`p.
But relative to Petitot's mathematical treatments, 
I would argue that `q.experimental` formalisms 
are even more significant departures from a 
philosophical paradigm which essentially 
reduces formalization in general to a 
presentation of logical-axiomatic reconstructions 
of empirical (emergent, higher-scale) phnomena.  
The rationale behind exercising a new type theory 
via concrete software exemplifications rather than 
via a theorem-driven mathematical treatment 
is that essential structural details may be 
evident in th concrete implementation which get 
lost in a mathematical reduction.  After all, 
the principle of `q.Turing equivalnce` sugests 
that at some mathematical level all programming 
languages are behaviorally indistinguishable.  
Insofar as grammatical or pragmatic differences 
between programming languages are nonetheless 
interesting as case-studies for semiotic or 
philosophical themes %-- insofar as programming 
languages, while `q.constructed` and constrained by 
the need to manipulate computer operations as 
well as express coding intent for the benefit of 
other programmers, are still `q.languages` and 
can suggest insights for human languages as 
well %-- the fact that higher-level programming 
structures get reduced away under mathematical 
treatments of programming languages shows that 
treating these languages as just mathematical 
objects is not a useful theoretical maneuver 
in this contexts.  After all, several 
high-level features of some programming languages %-- 
including Object-Orientation, monads, functional 
side-effects, continuations, type coercion, and 
lambda abstraction %-- have been studied as 
potential formal models of Natural Language 
features as well.  These analyses clearly 
require and presuppose a theory of 
programming languages where Objects, monads, 
effect-systems, and the like are first-class 
posits rather than epiphenomena that get 
analytically erased under mathematical 
reduction.      
`p`

`p.
But such a non-reductive theory of programming languages 
arguably needs to be `q.experimental`/, centered on 
these languages as software artifacts, whose properties 
and behavior are tested empirically.  If 
progreamming languages are also case-studies for 
phenomenology, their status as formalizations is 
likewise experimental %-- phenomenology 
grounding itself in a science that is 
observational rather than logico-mathematical; 
that progresses by practical tinkering 
rather than by asserting axioms and proving theorems.
`p`

`p.
This experimental modus operandi does not only 
affect how research proceeds; it also alters 
how research intersects with the txtual and 
publishing ecosystm.  If computer code is 
an essential part of an autgor's argumntation, 
then the author is responsible for curating a 
code base as well as perfecting a written 
exposition.  The publication itself does not only 
exist as a book or article but extends also to 
an open-source repository which needs tobe 
used and maintained.  The author herself 
presents as competent in the technological and 
computational skills associated with 
creating and maintaining an open-source repository 
as well as in the subject-matter covered in 
academic text.  Disciplinary expertise is 
complemented with literacy in practical tools 
needed to work with repositories, like
GitHub and the GNU Compiler Collection.
`p`

`p.  
There is also a more subtle sense that curating a 
complex code base demands %-- or brings forth %-- 
an experimentalist attitude that stands 
apart from the conventional style of philosophical 
thought.  Software development is 
unapologetically trial-and-error, ad-hoc, 
intuitive, relativly informal %-- the 
programmer is a hacker as much as a scientist.  
In the landscape of 20th-century philosophy, 
software development is metaphorically 
post-modern, perhaps Deleuzian.  It reaches 
asymptotically toward formal precision 
%-- this is a precondition of any commitment 
to software quality %-- but tries 
to achieve formal guarantees through a crucible of 
trial-and-error and test-and-failure.  
The programmer who writes software as 
part of a research project is suspended between 
two different regimes of scientific rigor, 
or communicative rationality %-- the software 
itself is (albit in digital incarnation)  a
`i.thing`/, which hoperfully does what it is 
supposed to, a mechanical ventriloquist endorsing 
th author's claims.  What software offers the research 
ecosysem is a raw performativity that transcends 
disciplinary boundaries.  We can dispute the author's 
claims and how much leeway we grant the 
author in defending these claims, but not 
the behavior of the software itself.  The author's 
`q.hacker` persona lifts her outside of any 
institutional or disciplinary enclosure other than 
the push to get `i.this` code to work, this 
one further piece to the puzzle.  But any claim 
that software %-- apart from its practical uses 
%-- by its very implementation serves as a kind 
of warrant for scientific or philosophical 
claims brings us back to a communicative 
and disciplinary rationality %-- the onus is 
on the author to justify that her software's 
behavior demonstates some principle of 
acadmic interest, something outsid itself.  In my 
case the relevant claim would be, for example, 
that the code paired with this paper demonstrates how 
Channelized Type Theory or `q.annotative fusion` is a 
credible and practically useful model of computation.   
`p`

`p.
But at least when evaluating these claims we're not 
just talking about philosophical arguments and 
the intellectual ecosystms where philosophical discussions 
happen %-- the journals, classrooms, and conferences.  
We're also talking about software and technology 
%-- something that can be downloaded, experimented 
with, improved, fully transparent.  The 
ad-hoc rationality of this transparency is somewhat 
different than the partial obscurity of peer review, 
closed-access journals, monetized conferences, 
or disciplinary exclusivity.  Software is not 
a degree.  This transparent rationality is 
perhaps a natural complement to phenomenology's 
`q.to the things themselvs`/.  Software is, 
par excellence, expertise in the thing itself.  
Software is intellectual cryptocurrency; the 
intelligence of the digital challenging 
the rigor and scientificity of the 
brick-and-mortar and the institutional.  
As the mortar unifying a research community 
software is syndicalistic rather than 
hierarchical.  But in this sense collaborative 
software development %-- as well as the communal 
evaluation of published software %-- is an 
intriguing instance of Habermassian discourse 
communities.  Software can help lead philosophy 
back to its Habermassian ethical wellspring. 
`p`

`p.
Perhaps ironically, the thread developing 
phenomenology in its most `q.Naturalizing` 
and scientific aspirations is also a 
gateway to an experimental, even `q.post-modern` 
and even political and politicized temperament.  
The Analytic and the existential-political 
trajectories of phenomenology are not 
so far apart, after all. 
`p`

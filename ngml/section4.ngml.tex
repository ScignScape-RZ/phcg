\section{Procedural Networks and Link Grammar}
\p{My goal in this section is to incorporate Link Grammar into 
a phenomenological and Cognitive Grammar perspective, more 
than to offer a neutral exposition of Link Grammar theory.  
Therefore I will accept some terminology and exposition 
not necessarily originating from the initial 
Link Grammar projcts (though influenced by 
subsequnt research, e.g. [expectation]).  I also 
want to wed Link Grammar to my own semantic intuitions, 
set forth earlier, that word-meanings and morphosyntactic 
interpretations should be grounded on pre- or para-linguistic 
cognitive \q{scripts} that are activated (but not 
structurally replicated, the way that according 
to truth-thoretic semantics linguistic form 
evokes-by-simulating propositional form) by linguistic 
phenomena.    
}
\p{Link Grammar is, depending on one's perspective, either related 
to or a variant of Dependency Grammar, which in turn is contrasted 
with \q{phrase structure} grammars (linguists tnd to designate 
competing schools with acronyms, lik \q{DG} for Dependency Grammar 
and \q{HPSG} for Head-Driven Phrase Structure Grammar).  
Link and Dependency Grammars define syntactic structures in 
terms of word-pairs; phrase structure may be implicit to 
inter-word relations but is not explicitly modeled by 
DG formalisms \mdash{} there is typically no representation 
of \q{noun phrass} or \q{verb phrases}, for example.  
Phrase structure is instead connoted via how relations 
fit together \mdash{} in \q{rescued dogs were fed}, for instance, 
the adjectival \q{rescued}-\q{dogs} relation interacts 
with the \q{dogs}-\q{fed} (or \q{dogs}-\q{were} plus 
\q{were}-\q{fed}) predication, an interaction that in a 
phrase-structure paradigm is analyed as the noun-phrase 
\q{rescued dogs} subsuming the noun \q{dogs}.  Dependency 
analyses often seem more faithful to real-world semantics 
because, in practic, phrases do not \i{ntirely} subsume 
their constitunt parts.  Linguistic structure is 
actually multi-layered, where semantic and morphosyntactic 
connections resonate between units within phrases separate and 
apart from how linguistic structure is organized into 
phrasal units themselves.
}
\p{Except for phrases that coalesce into pseudo-lexemes 
or proper names (like \q{United Nations} or \q{Member 
pf Parliament}), or indeed become shortened to single 
words (like \q{waterfall}), we perceive phrases both 
as signifying units and as aggregate structures 
whose detailed combinative rationale needs contectualization 
and interpretation.  In short, phrases are not \q{canned} 
semantic units but instead are context-sensitive performances 
that requir interpretive undrstanding.  This interpretive 
dimension is arguably better conveyed by DG-style models 
whose consituent units are word-relations, as opposed 
to phrase-structure grammars which (even if only by notational 
practice) give the impression that phrases conform 
to predetermined, conventionalized gestalts. 
}
\p{While Link and Dependency Grammars are both contrastd 
with phrase-structure grammars, Link Grammar is also 
distinguished than mainstream DG in terms of how 
inter-word relations are conceived.  Standard DG 
recognizes an assymetry between the elements in word-relations 
\mdash{} one element (typically but not exclusively a word) is 
treated as \q{dependent} on another.  The most common case is where 
one word carries greater information than a second, which 
in turn adds nuance or detail \mdash{} say, in \q{rescued dogs} 
the second word is more essential to the sentence's meaning.  
This potentially raises questions about how we 
can actually quantify the centrality of one word or another 
\mdash{} in many cases, for instance, the conceptual 
significance of an adjctive is just as trenchant as the 
noun which it modifies.  In practice, however, the salient 
aspect of \q{head} vs \q{dependent} assymetry is that any 
inter-word pair is \q{directed}, and one part of the relation 
defined as dependent on another, however this 
dependency is understood in a given case.
}
\p{By contrast, Link Grammar dos not identify a head-dependent 
assymetry within inter-word relations.  Instead, words 
(along with other lexically signifant units, like 
certain morphemes, or punctuation/prosodic units) are 
seen as forming pairs based on a kind of mutual 
incompleteness \mdash{} each word supplying some structural 
or signifying aspect that the other lacks.  Words, then, 
carry with them different varieties of \q{incompleteness} 
which primes them to link up with other modls.  Semantic 
and grammatical models then revolve around tracing 
the \i{gaps} in information content, or syntactic 
acceptability, which \q{pull} words into relation 
with other words.  This approach also integrates 
semantic and syntactic details \mdash{} unlike frameworks 
such as Combinatory Categorical Grammar, which 
also treats certain words as \q{incomplete} but 
identifies word connctions only on 
surface-level grammatical terms \mdash{} Link Grammar 
invites us to explore how semantic and 
syntactic \q{completion} intersects and overlaps. 
}
\p{}
\p{}

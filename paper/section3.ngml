
`section.Channels and Edge Diversification`
`p.
Graph representations have obvious applications 
to modeling computer code and computations.  
Intuitively, consider procedures as nodes; 
edges incoming to or outgoing from nodes 
then may represent the value passed into or 
returned from procedures.  In order to be a 
reasonable code representation, however, this 
model has to capture further details via 
edge-annotations, grouping nodes and/or edges 
into higher-level units, or similar hypergraph 
constructions.
`p`

`p.
As I argued last section, hypergraphs are useful target 
for general-purpose programming language parsers because 
these general languages tend to have relatively complex 
grammars and special syntactic contexts.  While 
programming languages in a theoretical sense may 
have an expected translation to Abstract Syntax Trees, 
real-world languages embrace syntactic forms 
that complicate this abstract picture.  Earier I cited 
`Csharp;'s `LINQ; as an example of an intra-linguistic 
special syntax; other examples include embedded `XML; in 
Scala; attribute markings in `Csharp; and `Java;; 
template metaprogramming in `Cpp;; regular-expression 
syntax in languages like `Perl; and `Ruby;; and so 
forth.  I have argued that a hypergraph (rather than 
graph or tree) paradigm is a more natural foundation 
for representing code in these practically evolving 
languages, which are designed around semantic expressiveness 
rather than an `i.a priori` commitment to theoretical 
compilation models. 
`p`

`p.
As I will focus on in this section, similar comments apply to the 
semantics of procedures and function-calls.  The `q.mathematical` 
picture of procedures as functions mapping inputs to outputs is 
only approximately accurate in the context of modern programming 
languages.  One issue is that the distinction between input and output 
parameters is imprecise, given that input parameters can be 
modifiable references.  A common `Cpp; idiom, for example, 
is to pass a non-constant reference instead of returning 
relatively large data structures %-- mutable references 
are technically an input rather than output value, even 
if the intent is for a called procedure to supply data for 
the mutable input (this technique avoids extra copying of 
data).  Another complication is that procedures can have multiple 
sorts of input and output: e.g., throwing an exception rather than 
returning a value.  Likewise, Object-Oriented languages' 
`q.message receivers` are input parameters with distinguished 
properties as conmpared to normal inputs.
`p`

`p.
Since programming notation visually distinguishes procedure inputs 
from outputs, it is easy to think of the input/output distinction 
as mostly syntactic.  The significant differences, however, 
are more semantic.  Consider a `Cpp; function which returns an 
integer: it is a compiler error to return from such a function 
without suppying a value; also, the called procedure has 
no access to the memory which would hold the return value.  
By contrast, a function which takes a non-constant 
integer reference is not forced by the compiler to 
modify that value, nor prohibited from accessing the 
input's value.  This points to the practical differences 
between returning values and altering input references, but it 
also indicates that inputs can be treated as `i.de facto` 
outputs by adhering to usage conventions %-- a reference 
mimics the behavior of a return value to the extent that 
procedures initialize the reference on all execution paths, and 
refrain from using any value which the reference might 
have before the procedure starts.  Generalizing this point, 
the badic contrast between input and output can be 
seen as a semantic matter of usage protocol, rather 
than a syntactic contrast between passing valued to a 
function vs. accessing a function's returned result.
`p`

`p.
Of course, input and output are usually both distinguished 
and interconnected by how outputs are used as inputs to 
other functions.  With respect to procedures which take 
one parameter, the general function-composition operator 
`fOfG; takes the output of `gFun; as the input to 
`fFun;.  We could of course define a different operator 
where `gFun; and then `fFun; both run, taking the same 
value (potentially a reference-type value that `gFun; 
could potentially modify before `fFun; runs).  The 
former (composition) operator establishes an inevitable 
dependence of `fFun; on `gFun;: `fFun; needs `gFun;'s 
output for an input value.  The second case is less obvious 
%-- in a sequential call like `fAfterG; (`gFun; runs then 
`fFun; runs %-- I notate the relation with an inverted 
semi-colon to highlight the parallels with `fOfG;, but 
the analogous case in practice would be `gThenF;), 
there may or may not be a `gFun; side-effect that 
infuences `fFun; (even if they are passed the same 
inputs).  So inputs and outputs are distinguished 
by how output-to-input links %-- outputs from one procedure 
becoming inputs to another %-- have certain semantic 
properties in the context of functional composition, and by 
extension the relations between precedures which 
run in sequence.  Again, though, this call for a semantic 
analysis which looks beyond languages' surface syntax for 
function calls, and how usages of return valued are notated.
`p`

`p.
Mutable references and procedures-with-side-effects expose limits 
in the representational expressivity of graphs (even hypergraphs) 
for modelling inter-procedure relationships.  Consider a case 
such as represented in Figure~\ref{fig:figGF} 
`input<figGF>;, where `gFun; modifies 
input $n$ that is then also input to `fFun;.  Here `gFun;'s 
effect on `fFun;'s input is marked by a `gFun;-to-`fFun; 
arrow, but this directed edge implies a different semantic 
relation than `gFun;'s output being `fFun;'s input 
(as in `fOfG;).  The specific difference can be visualized 
in a scenario like Figure~\ref{fig:figGFcomplex},`input<figGFcomplex>; 
based on code such as written below the 
graph.  The situation here is that `fFun; both uses 
`gFun;'s output return (via the symbol $z$ the value is assigned to) 
and also the values held by $x$ and $y$ which are altered by 
`gFun;.  I notate these dependencies by grouping the `gFun;-to-`fFun; 
edges through $x$ and $y$ separately from the edge 
with $z$ %-- the latter edge conforms to the relation of 
a procedure taking another procedure's output as input 
(although here the relation is indirect through a 
lexically-scoped symbol), but the former edges reflect a 
different inter-procedure pattern.  The point of this 
example is that separating input and output edges is not 
enough to express program-flow semantics in anything but 
pure functional languages %-- even given the `q.hypergraph categories` 
strategy of grouping input an output values into hypernodes.
`p`

`p.
For situations like these I propose a notion of `i.channels`/, which are 
higher-scale groupings of edges analogous to how hyperedges 
involve higher-scale groupings of nodes.  In Figure~\ref{fig:figGFcomplex}, 
for instance, the $x$ and $y$ edges can be considered a separate 
channel than the $z$ edge, because $x$ and $y$ bridge `fFun; and `gFun; 
according to one sort of program-flow semantics (with side effects and 
mutable inputs passed to sequential procedures) while $z$ follows a 
different pattern (with output values and lexical symbols).  
The shaded box in the figure shows the core role of channels, 
grouping together edges that have some particular connection 
which could not be expressly identified by other means (like 
shared annotations) and also isolating edges and edge-groups 
from other elements (here, isolating the $x$-and-$y$ pairing 
from the $z$ edges).   
`p`

`p.
This case illustrates the basic premise of channels as 
distinguished and/or edge-groupings, and also one modelling 
domain where I contend channels can be applied; specifically, 
representing details in computer code (in a general hypergraph 
representation of source code) such as program flow.  
To discuss channels as graph elements further, I will 
start by examining channels in the specific computer-code 
context, which calls for a detour review of 
certain semantic structures central to the semantic of computer programs. 
`p`

`p.
`parlead.Typed Values and `q.Careers`/`  It is commonly accepted that a 
theory of types %-- with at least some details adopted from mathematical 
type theory %-- is a necessary component of a rigorous treatment of 
computer software and programming languages.  However, we should not 
neglect to keep in mind the specific realities of programming 
environments that complicate such basic notions as types' 
instances, the nature of entities that we should deem to be 
bearers of types, the status of special (non-)values like 
`lstinline.null` or `q.Not A Number`/, and related details that 
contrast programming `q.types` from mathematical sets or `q.spaces` 
in various incarnations (sheaves, topoi, etc.).  
`p`

`p.
In particular, the `q.instances` of types (at least in the programming-language 
context) are not particularly suited to the intuitions of `q.members` of 
sets, or `q.points` of spaces.  One reason is that there is no fixed theory 
of types' extension, or `q.set` of possible instances,
in a given computing enbironment.  For example, types without a fixed size 
in memory %-- say, lists of numbers %-- are constrained be a computer's 
available memory.  We cannot be certain which lists are small enough that a 
given environment can hold them in memory, so that they are available 
as typed values for a program.  Conceptually, then, 
types are very different from sets of values. 
`p`

`p.
More significantly, types' instances do not have a kind of 
abstract self-sufficiency like points in a mathematical space.  
Consider how computational procedures deal with `q.values`/, the 
things that are representatives of types.  Most values which 
procedures encounter are produced by other procedures, either 
passed as parameters from calling procedures to called procedures, 
or returned as outputs from called procedures to calling procedures.  
`p`

`p.
Of course, programs execute in a world of surrounding data %-- on computer 
drives and in memory, plus `q.cyberphysical` data from devices 
hooked up to computers (at a minimum, devices crafted to be 
part of a computer set-up, like mice and keypads; plus often 
`q.smart` devices which software accesses to manage an oversee).  
From a programmer's point of view, this data is accessed by 
calling specific functions, albeit ones which 
(at the lowest level) programmers themselves do not 
implement (viz., the procedures exposed in device `q.drivers`/).  
Analogously, many values are presented directy in source-code 
literals; but we should think of these values as likewise 
yielded from procedures that read source tokens or strings 
and interpret the intended type-spefic value (e.g., converting the 
character-string `q.123` to the corresponding integer).  
Typically these `q.reader` procedures occur behind-the-scenes; 
although, which helps demonstrate the point that source literals 
involve implicit function-calls, some languages support 
`q.user-defined` literals with nonstandard syntax %-- 
consider `Lisp; `q.reader macros` and `Cpp;'s 
`lstinlinestyle.`operatorqq;`/.
`p` 

`p.
Consequently, analysis of programs and computer code should 
proceed from the perspective that all typed values are introduced 
into a running program as results of procedure-calls.  We therefore 
have extra detailing in any context where we would talk 
about `q.typed values`/.  The situation could be analogously 
compared to settings like approximation theory %-- consider an 
analysis according to which a spatial magnitude, say, is not 
just a real number but the result of a measurement operation.  
By extension, quantities that on purely mathematical 
terms might be treated as points in spaces such as the real 
number line are `q.packed` into `i.observations` which can be 
sites carrying further information, such as an approximation 
factor.  My point is not that computer programs fail to work 
with exact values %-- in a typical case a single typed value 
does not need an approximation `q.window` unless the software 
is manifestly interacting with physical systems where measurement 
uncertainty is taken into consideration.  However, approximation 
as `q.extra structure` is a useful analogy for the 
added detail latent in programming theory given that 
typed values are not `q.freestanding` mathematical entities 
but are always packaged into digital structures that make 
them available for software procedures.
`p`

`p.
For sake of discussion, I will use the term `i.carriers` to 
describe the structures that `q.package` typed values.  
When a procedure returns a value, said value is embedded 
in a carrier which `q.transports` it to other procedures.  The 
`q.things` exchanged between proceures are actually, then, 
carriers rather than values %-- we should picture 
carriers travelling on `q.routes` laid out in source-code 
hypergraphs.  Carriers, in particular, are more general 
than values.  Consider a function which, on one occasion, 
throws an exception rather than returning a value.  The carrier 
arranged to hold the return value is therefore empty.  Carriers, 
then, can be in a `i.state` other than that of holing a valid, 
initialized value.  Some programming language accommodate these 
cases via special `lstinline.null` or `lstinline.Nothing` values, 
but these are still constructs inside the language's type 
system.  Thinking in terms of carriers, instead, removes 
certain `q.states` from the type system: an empty or 
pre-initialized carrier does not have some special `q.empty` 
value; it does not have a value at all.  Similar comments 
apply to carriers which hold values which were once valid but are 
no longer so, like deleted pointers.  Any carrier potentially has a 
`q.career` which starts with no value then is initialized 
with a value (and maybe gets updated over time); and may then 
`q.retire` and cease to hold a legitimate value.  Only in the 
middle phase of this trajectory does the carrier's range of 
possible states correspond with potential instantiations of 
a type (I assume here that each carrier is associated with 
one canonical type).  
`p`

`p.
`parlead.Carriers and Categories of Types`/.  In some contexts it is 
useful to examine a type system `tys; via a category `tyCat; of 
types (such as, the category `HaskCat; of Haskell types).  
Carriers are an extra structure which rest `q.on top of` 
types, calling for the foundation (including Category-theoretic 
treatment if applicable) to be reconsidered.  First, 
the Haskell-like interpretation of `tyCat; morphsims 
should be redefined.  On the usual account, `tyOneToTyTwo; morphisms 
are functions mapping type `tyOne; to `tyTwo;.  This 
picture is complicated by procedures deviating from pure functions: 
as I discussed earlier in this section, the input/output discussion 
is complex and does not precisely map to the mathematical model 
of morphisms between Category-objects.  Instead, inter-type 
morphisms (to the degree that these are idetified as categorial 
morphisms establishing type systems as categories) should be restricted 
to specialized semantic associations between types, such as 
casts from integers to floating-point values (hence, morphisms between 
integer types to floating-point types).
`p`

`p.
Moreover, reasonable type systems have a nontrivial collection of 
endofunctors marking inter-type associations.  A good example 
is the `q.unreferencing` operator which recovers the underlying 
type `ty; from a relerence type `ty;\&.  This operator naturally 
translates to a function `ty;\& $\rightarrow$ `ty; that retrieves the 
value held by a reference.  It is reasonable to treat this 
function as a `ty;\& $\rightarrow$ `ty; morphism.
`p`

`p.
In a general case, though, implemented procedures should be treated 
apart from such basic morphisms that tie a type sytem together: a 
general procedure which takes a `tyOne; input and outputs `tyTwo; 
is not a `tyOne; $\rightarrow$ `tyTwo; morphism but a more complex 
structure operating on carriers.  For each input and output parameter 
there is a carrier accessible in the environment of the procedure 
(its program code and its runtime environment) that provides the 
procedure acess to an underlying value.  The specific access can be 
modeled around different sorts of carriers %-- carriers holding 
return values should allow procedures to `q.write upon` (initialize or 
modify) their values but not read them (conformant to the expected 
semantics of `q.procedural output`/).  In this theory, the 
output carrier from one procedure is distinguished from the 
input carrier for another procedure, even in a case where one's 
output is directly used as the other's input.  To illustrate, 
Figure~\ref{fig:figGFc} `input<figGFc>; shows a modified 
version of Figure~\ref{fig:figGF} where the `gFun;-to-`fFun; 
edge is annotated by a pair of carriers (output and input 
differentiated by solid vs. double borders).  Similar to 
Link Grammar (see the last section), a single edge bears a 
double-annotation to indicate that the edge depends on some 
notion of compatibility: in particular, output-to-input 
carriers can only be linked if they hold the same type 
(or at least interconvertible types).  As such, a double-annotated 
edge captures a situation where the value in one carrier is 
transferred into a second carrier %-- potentially with a type-cast or, 
e.g. in `Cpp;, a behind-the-scenes call to a copy-constructor.  
I will refer to such a value-transfer as a `i.handoff`/.  
A `gFun;-to-`fFun; (hyper-)edge therefore expresses added details 
because its annotations convey properties of carriers whose state 
and compatibility determine the value-transfers that enable 
inter-procedure relations, such as one procedure calling and/or 
using the output from a different procedure.  
`p`

`p.
In lieu of mostly theorizing type categories, then, we can 
also consider a category `CarCatS; of carrier `i.states`/, which 
generalize typed values.  A morphism in `CarCatS; represents either a 
change in state or a mapping between values.  When a carrier `cCar; is 
initialized, it transitions from being in a state with no value 
to being in a state where it holds an instance of its type 
(when a carrier is already initialized its state can change 
by repacing its held value with another value; or by 
becoming `q.retired`/).  A `cCarOne;-to-`cCarTwo; `q.handoff` then 
corresponds to a morphism in `cCarTwo;'s state wherein 
`cCarTwo; (perhaps transitions out out a pre-initialized state and) 
acauires a concrete value derived from `cCarOne;'s.  
This case %-- I'll call it a `q.handoff-induced morphism` 
%-- plays a foundational role in analysis via carriers and 
hypergraphs analogous to `tyOne; $\rightarrow$ `tyTwo; morphisms 
in conventional category-theoretic program semantics. 
`p`

`p.
After accounting for this change in perspective, many concepts of hypergraph 
categories appear to carry over to this theory.  Rather than morphisms 
in a type category `tyCat;, (hyper-)nodes in this case represent 
procedures, and their surrounding edges represent (via annotations) 
carriers accessible (as inputs or outputs) to the procedure's 
implementation.  Morphisms are represented `q.within` these 
edges insofar as a procedure being called induces a change in state 
for carriers along the procedure's incoming edges 
(likewise, returning values induces state-changes among 
outgoing edges).  
`p`

`p.
In practice, procedures call other procedures.  A procedure's 
input carriers can be augmented by a `q.lexical scope`/; 
a repository of local carriers (syntactically speaking, 
lexically-scoped source-code symbols) which start as uninitialized but 
can hold outputs from other procedures called from the current 
procedure's implementation body.  Each implementation is then a 
sequence of further procedure call wherein the calling procedure 
assembles the requisite local carriers to provide inputs to 
the called procedure (via handoffs).  The calling procedure 
must also provision carriers to hold the called procedure's 
output.  In effect, the calling procedure must orchestrate a 
suite of handoffs among its own carriers and the those 
of the called procedure.  The semantics of this multi-faceted 
sum of carrier-transfers can be represented within a source-code 
graph; and so, the structures and semantics of these hypergrah 
representations should be codified in a manner which 
renders (a de-facto Ontology) the patterns of aggregate 
carrier handoffs). 
`p`

`p.
To illustrate, Figure~\ref{fig:figGFcomplexc},`input<figGFcomplexc>; modifies 
Figure~\ref{fig:figGFcomplex} so as to show carriers and handoffs, 
analogous to Figure~\ref{fig:figGFc} adding carriers to Figure~\ref{fig:figGF}.  
Each case where one procedure calls another can be modelled via a 
graph which groups together the carriers (seen in the context of the 
calling procedure) that are packaged together to enable the call; 
and concordantly the links between these carriers and those 
in the called procedure's signature and implementation which 
embody handoffs executed in the transition in program flow between 
the calling procedure to the called procedure, and back.
`p`

`p.
`parlead.Carriers and Channels`  The theory of channels comes 
into effect insofar as we combine this carriers and handoffs 
model with my earlier discussion of differentiating input and 
output varieties.  For instance, inputs may be Object-Oriented 
message-receivers or normal parameters; outputs may be 
thrown exceptions or normal returns.  In the hypergraph framework 
I just outlined, hyperedges carry double-annotations to 
mark the pairs of carriers involved in a handoff within a 
procedure-call.  Grouping carriers based on their common 
semantics %-- separating the `this; object from non-distinguished 
parameters, let's say %-- involves a further level of organization, 
grouping hypereges into channels.  Taken together, then, the 
overall hypergraph system exhibits two generalizations from 
simpler code-graphs: double-annotations on edges (based 
on carrier theory) and the use of channels to reflect 
higher-level programming semantic, such as the distinct status 
of method-receivers as non-standard input and of exceptions 
as non-standard output.`footnote.My chapter in 
`cite<NathanielChristenCyberphysical>; includes examples of other 
more `q.exotic` kinds of channels as well.`  
`p`

`p.
To develop this unified theory, we can consider a `i.channel` as 
(semantically) a (possibly empty) collection of (one or more, 
if not empty) carriers %-- the corresponding hypergraph representation 
is a channel grouping edges whose annotations refer to these 
carriers.  Each channel is then associated with a specifis 
`q.protocol`/, an idiosyncratic method for procedures to 
interact with carriers (and by extension with one another).  
For example, the procol for regular input and output channels 
is that one output carrier's value can be directly `q.handed off to` 
an input carrier, as in `fOfG;-like composition.  In many languages a 
procedure can have at most one output value, and also at most one 
`q.message receiver` (`this;) object.  Accordingly,
a procedure-call can bundle the output channels from multiple 
other procedures to populate some further called procedure's 
input parameters.  Since there is only one `q.`this;`/, 
two methods can be combined (modulo type compatibility) by inserting 
the prior method's output as the next method's message-receiver 
(handing off the output value to the next `this; carrier), 
giving rise to `q.method chaining` (such call-sequences can continue 
over multiple steps).  Meanwhile `i.exceptions` cannot be treated 
as normal values (you cannot in most cases hand off between an 
`q.exception channel` and normal carriers).  Instead, 
procedures which want to `q.catch` exceptions need special 
structures, like catch-blocks, which provide the atypical 
carriers that can actually hold exception values (and so 
receive exception-channel handoffs.
`p`

`p.
All of these are customary coding structures and design patterns which 
regulate how modern programming languages handle features like 
method-calls and exceptions.  These patterns, which I am theorizing here 
according to channels' semantic protocols, are not primarily grounded 
in a language's type system but rather in regulations on procedural 
flow and program organization that are orthogonal to type restrinctions.  
I contend that a theory of channels can unify the regulations enforced 
by strong typing (e.g. not calling procedures with incompatible 
arguments `visavis; expected types) and those due to inter-channel 
semantic protocols.  What the two semantic regimes have in common 
is that they ultimately maniest as rules on carrier-transers %-- 
both carriers' types and the kinds of channels to which they 
respectively belong influence whether a purported handoff 
(needed by a call between procedures) is permissible; if not, 
the code declaring the relevant procedure-call should not 
be accepted (it should not compile).  So, enumerating 
channel-semantic protocols is a way to formally model 
what inter-procedure relations are legal accoring to the 
program-flow and organizational principles of the 
implementation language, analogous to how procedure 
calls are evaluated for compliance with the 
language's type system.  The syntactic rules for how 
procedure-calls are notated are driven in part by 
inter-channel protocols (for example, using a dot 
to separate a `this; object from a method-name 
allows method-chains to be compactly written), but 
a rigorous model should take syntactic details as 
epiphenomena %-- the important details for hypergraph 
source-code models is the kinds of channels recognized 
by a language for inter-procedure communication, and the 
protocols associated with various channel-kind pairs 
governing how and when carriers in one channel may be linked 
by handoffs to carriers on other channels (of the same or 
other kinds).
`p`

`p.
One benefit of the channel-based framework I have presented here is 
that it provides an intuitive breakdown of procedure-calls into 
smaller steps.  A procedure call generally requires a structure involving 
multiple carriers to be present in the context of the calling procedure 
(while, on the called side, the procedure's signature provisions a 
set of carriers that receive values from the calling context).  
Preparation for the call therefore entails building up a set of 
carriers and establishing their respective links to carriers on the 
receiving end.  It is possible to divide this process into a 
series of minimal sets, each involving operations on a single carrier.
Via this interpretation, graphs modeling computer code 
with channels an carriers can be translated into 
sequences of minimal carrier-related instructions, which in turn can 
be executed as a kind of virtual machine.  
The scripting environment I am using in this paper for 
demonstration %-- which in the last chapter I covered 
mostly from a grammar and parsing angle %-- therefore 
culminates in data structures constituting an Intermediate 
Representation used by a runtime engine to translate the 
compiled code to internal (mostly `Cpp;) function-calls.  
This involves two software components %-- an algorithm to 
walk through code graphs to generate Virtual Machine code 
and then a runtime library to execute the code thereby 
generated.  I will briefly summarize both components 
as case-studies in how hypergraph code representations can 
be transformd into concrete execution environments.
`p`

`p.
`parlead.A Hypergraph-Based Virtual Machine`  According to channel theory, 
an operational execution environment is, first an foremost, a 
`q.virtual machine` which defines and operates on carriers, packages them 
into channels, and then uses bundles of channels 
as specifications for procedure-calls.  When `i.creating` virtual machine 
code, we can then proceed by stepping through graph elements representing 
channels and carrier, emitting data as needed to reconstruct 
channels via minimal operations.  When `i.running` virtual machine 
code, the important step is packaging groups of channels into a 
single data structure (for each distinct procedure call) and then 
mapping the resulting structure to a binary array which mimics the 
`ABI; (Application Binary Interface) of target procedures %-- so 
as to produce function-calls via the virtual machine which, at the 
binary level, appear to be the result of compiled (e.g., `Cpp;) functions.
`p`

`p.
Listing~\ref{lst:figPVM} depicts part of a virtual machine file generated 
by the demo from a script-like source file.  This kind of file 
(which I call `PVMIR;, for `q.Phaon Virtual Machine`/) 
is the final output of the compiler pipeline described in this and 
the last section.  The basic premise behind this format is that 
every procedure call can be associated with a `i.channel package`/, 
each of whose channels is a stack of carriers.  It is straightforward 
to generate `PVMIR; code tracing a series of instructions to 
recreate a channel package held as a structure (in the demo, 
a `Cpp; object) in memory.  Moreover, the `q.Phaon Graph` format is 
designed to represent information associated with channels and 
carriers; so generating `PVMIR; (at least on the level of 
individual procedure calls) is facilitated by 
constructing graphs in the `q.Phaon` format to begin with.  
I use the term `q.RelaeGraph` for graphs generated from 
`q.relae` parsers; in the overall pipeline then the transformation 
from Relae-Graphs to Phaon-Graphs is the important 
step which enables the `PVMIR; generator to run mechanically.  
`p`

`p.
As desribed, `PVMIR; plays a limited role insofar as it is 
generated from channel-package objects %-- yielding 
`PVMIR; files %-- and then sometime later a virtual machine 
runs the `PVMIR; code to recreate those objects at runtime.  
In this role `PVMIR; just allows the channel-package objects 
to be encoded in a text file for later use.  
However, `PVMIR; is more than only a serialization format 
for channel packages.  The extra roles for `PVMIR; come 
into play when defining source-code-level procedures 
(which includes code blocks, e.g. `lstinline.if-then-else` 
alternatives, which are implemented as anonymous procedures).  
Because `PVMIR; represents a seauence of minimal carrier-related 
operations, certain such sequences may be isolated as separate 
subroutines, which in turn can be assigned unique-identifier 
and called within the virtual-machine runtime as 
`q.virtual` functions.  
`p`

`p.

`p`

`p.

`p`

`p.

`p`

`p.

`p`



`subsection.The co-framing system and the doxa system`
`p.
It may be argued that a `q.change-initiation` semantic 
theory such as I have laid out is, in fact, circular.  The 
meaning of my assertion that this wine is Cabernet Franc 
is, by that theory, the change that occurs in your 
cognitive frame as and if you trust my claim.  But presumably the 
only reason you do this is because you understand my 
enunciation as presenting some proposition, which you can 
accept to be true.  In order for my language to update 
your beliefs (or indeed to fail to do so, 
if you doubt me), you have to entertain 
propositional attitudes to the content of my 
language.  Indeed, yur propositional attitudes have to 
structurally integrate with mine: I am evoking that 
wine's being Cabernet Franc as an assertion and 
not a question or request.  So you have to identify 
my attitude to some proposition and on that basis 
formulate your own attitude to the same proposition.  
This can only work if my language signifies some 
proposition %-- so why can't we call 
that proposition the `q.meaning` of my 
utterance, rather than the effect which my declaring 
said proposition in some attitudinal package has on you?  
`p`

`p.
The rationale for this challenge would seem to be 
that propositional content does not belong exclusively 
to one or another person, or even to the participants 
in a conversation.  Sure, many referential and conceptual 
details `i.are` context-specific.  But our joint 
process of cognitive framing seems intended to 
align our respective frames so that a genuine propositional 
content can emerge %-- as we resolve all pronouns, follow all 
anaphora, and agree on all conceptual roles.  Hence 
from `q.that wine is Cabernat Franc` we can arrive at a 
content that thematizes the viniferous 
properties of some particular liquid.  Our interpersonal 
negotiations may be required to converge our attention on 
`i.that particular` liquid, but %-- once we are there %-- the fact of 
its being Cabernat Franc (and any other culinary, chemical, physical) 
properties is independent of our collective and individaul 
framing.
`p`

`p.
That is, there is a nugget of propositional content that can be 
designated in a context-neutral way.  That content is 
expressed `i.in conversation` using `q.locally significant` 
terms, for convenience, but those details of `i.naming` 
the proposition involved are arguably tangential to 
the propoistion itself.  We can, for sake of discussion, 
imagine a more neutral naming: imagine we could give 
GPS coordinates for one glass at one stretch of time 
and thereby refer to the wine in the glass thereby located 
(call it W) and declare that W is Cabernet Franc.  
(Meanwhile, let's agree that the concept `q.Cabernet Franc` refers 
to a wine with a specific genetic profile %-- some property 
`q.CF` %-- i.e., `i.being CF` is an unambiguous biological 
property that exists outside of any branding or vinological 
contingencies).  It would 
seem as if my linguistic performance in terms like 
`q.that wine is Cabernet Franc` works because you 
recognize me to be claiming `q.W is CF`/.  
And the only obvious way that can happen is if what 
I say somehow `i.means` `q.W is CF`/.
`p`

`p.
Here I am recognizing the intuition that the effect 
which an asserting act has on addrssees is (skepticism 
aside) to accept the asserted content as true.  The 
intuition seems to be that the assertion is posed in the guise 
of something whose truth is independent of the effect it 
has on the addressee %-- it's not as if you `i.make` it true by 
aggreeing to it.  An implicit assumpion is that any competent 
person would also deem it true %-- a sommelier and a chemist 
would confirm that W is, yes, CF.  So the idea 
that meanings are propositional content %-- motivated by the 
intuition that assertorial effects depend on all parties' 
grasping a propositional content that can be lifted outside 
the immediate context %-- seems driven by 
the idea that parties `i.outside` the conversation would 
be equally disposed to view the assertions as truthful.
`p`

`p.
There is, of course, vagueness and context-sensitivity in 
language.  But that does not preclude massaging linguistic 
content to reduce or eliminate those contingencies %-- as if 
there is some subset of linguistic expression that has a basically 
pristine referential structure, one which allows a 
certain mathematical precision at least in the areas of 
designating natural kinds (and designating physical objects via 
spacetime regions).  So, `q.W is CF`/, involving only 
globally meaningful spatiotemporal and genetic designations, 
would be an example of such `q.pristine` language.  
And while people do not actually `i.talk` in that kind 
of language, we can argue that when our cognitive 
frames are correctly aligned, we communicate `i.as if` 
we were using pristine language.  The implication 
of this possibility is that semantics may indeed 
be logically transparent: the contextual complexities 
evident in surface-level language are biproducts of 
our cognitive autonomy, not intrinsic to language.  
They are facets of the minds which are the `i.vehicles` 
for language, and so from the perspective of linguistics 
proper they are `q.implementation details` rather 
than theoretical problems.  That is, we need to exert conscious 
effort to synchronize our attentional foci and 
conceptual mappings with others', given the private nature 
of our perceptual observations and `q.inner thoughts`/:   
this is why we have both linguistic and extralinguistic 
signifiers of perceptual frame (`q.this`/, `q.that`/, 
`q.there`/, `q.last summer`/, pointing), and a social 
infrastructure to conventionalize lexical and natural-kind 
meanings (why, for instance, usage like `q.corn sugar` is 
regulated, not only even by convention, but 
sometimes by law).  But `i.above and beyond that` we have semantic 
faculties that trade in propositional contents once 
we have achieved a proper alignment with our conversational 
peers %-- a process which itself involves language, 
but language in a different register, meta-discursive 
more than semantic.  
`p`

`p.
One way of describing this is to posit that what we 
call `q.language` is really two different 
systems: one that effectuates frame-alignment to 
compensate for the `q.centrifugal` force of cognitive 
autonomy, and a different architcture for 
signifying communication in the context 
of neatly aligned cognitive frames.  For convenience 
%-- to avoid debating whether this distinction merely 
reciprocates, say, prgamatics vs. semantics %--  
let's call this the `q.coframing` system and the 
`q.doxa` system.  We could 
also guess that the hard part of AI-driven 
Natural Language Processing is the co-framing 
system; the `q.doxa` system has enough logical 
polish that computers can play the game as 
well as people.  A robot in a testing room could geolocate some glass, 
take a sample to a DNA analyzer, test its profile against 
a database of cultivars, and conclude that `q.W is CF`/.  
Sure, we need human ingenuity to communicate effectively 
in the `i.absence` of `q.context-stripping` possibilities: 
we do not talk in terms of GPS coordinates and 
laboratory-testable property-ascriptions.  
But how do we deny that our context-dense language is 
possible only because there is a logical kernel that 
`i.could`/, in principle, be solicited in 
context-neutral terms?  
`p`

`p.
If I say that `q.the meaning of `i.this wine is Cabernet Franc` is 
its side-effect` %-- how it initiates a procss whose telos 
is your believing `i.W is CF` %-- I can be accused of circularity 
because I seem to presume what needs to be explained: that 
my language contains within it a signification 
of `i.W is CF` as propositional content.  On that objection, 
if my language did not carry that 
content, it would not cause the desired effect. 
And if it `i.does` carry that content, this given would 
seem logically prior to the side-effect, since the side-effect 
can happen only because of the carried content.  Ergo, apparently, 
the `i.real` meaning is the content, not the side effect 
(or the process or initiation of the process 
that has the side-effect).
`p`

`p.
To formulate the objection, I have tried to imagine a competent 
language-understander who responds to `q.pure` or de-contextualized 
propositional content.  My specific example was a robot who tests 
a wine sample to confirm `i.W is CF`/.  In the robot's computational 
capabilities, language only exists as logical structures: spacetime 
references are defined as geolocations and timestamps; adjectival 
qualities are defined as scientific properties computable 
in the relevant metrics (a genetic profile, a 
chemical signature, etc.).  We can imagine a cohort 
of intelligent robots listening in on our conversations and 
translating from our human context-sensitive language to 
their computable context-stripped reprsentations.  By thia 
thought experiment we can %-- or we can contemplate 
that we can %-- imagine robots for whom language communicates 
propositional content directly.  We can imagine sentences 
`q.naming` propositions the same way that first and last names 
identify people.
`p`

`p.
But is that what is happening?  If the robot wants to 
confirm `i.W is CF` it has to effectuate certain actions: roll 
to the right place, take the wine sample, 
test it, match the rsults to a database.  And even if 
the robot taks our ascriptions on faith %-- maybe it has a database 
that matches glasses to both GPS locations and wine styles, 
to record facts like `q.this glass has Cabernet Franc` %-- 
responding to my assertion still involves some 
activity (updating the database).  So even though 
we have attributed power to the robot to traffic 
in logically pure expressions of propositional content, 
we have not shown that the robot lies outside the side-effect 
cycles of language. 
`p`

`p.
Let's suppose that there is indeed a `q.doxa` system within 
language, so there is a space of logically pristine meanings 
conveyed via language.  As I proposed earlier, a `q.doxa` inventory 
%-- a set of provisional beliefs %-- forms part of each 
cognitive frame.  When our language-processing faculties 
encounter linguistic artifacts which express %-- or within the 
context of suitably constructed cognitive 
frames can be translated to %-- the `q.doxa system`/, 
we respond to those stimuli by (evaluating and then, 
often) adding the `q.signified doxa` to the `q.doxa inventory`/.  
But this is still a side-effect: the logical structure 
of the doxa has a role to play in this overall process, 
but this is far from authorizing us to 
reify the doxa as the philosophical core 
of linguistic meaning overall. 
`p`

`p.
To put it differently, th claim of circularity that I acknowledged 
is itself circular.  Yes, a side-effect due to newly 
believing `Pprop; would seem to depend on  `Pprop; being expressed 
as propositional content by any act initiating the side-effect.  
And `Pprop; is a propositional content that can inspire 
belief-change side-effect because it has the form of a 
trans-personal articulation: any reasonable person 
(even a robot) should accept it.  The circularity 
here is that the `q.work` is done by `Pprop;, not by the 
side-effect per se.  But in order to theoretically 
posit `Pprop; outside the side-effect, we have to posit a kind 
of decontextualized rational community: `Pprop; is 
logically distinct from the side effect because other people 
and robots should engage it too.  But their getting thus 
engaged is also `i.for them` a side-effect: to believe or 
test `Pprop; the robot has to perform certain acts %-- i.e., 
whatever software runs its language-comprehension modules 
has to call some function than run its database and/or 
motor-location modules.  The enunication of `q.that wine is 
Cabernet Franc` is still `i.initiating a process`/.
`p`

`p.
Insofar as my assertive speech-acts are rationally performed, 
their side-effects on `i.one` addressee should resemble 
their side-effects on others, including other hypothetical or potential 
addressees (even robots).  There is clearly then a kind 
of `q.publicness` or `q.communalization` of side-effects, 
and language seems logical if we get the impression that 
its effects on different listeners will be mostly the same.  
If there is circularity here, it seems to go two ways: 
arguably, side-effects can be similar because there is 
a logical nexus in language that fixes content
across minds.  Surely `q.Sanders is a presidential candidate` 
(stated as a simple fact, without polarity) evokes 
similar effects because it is objectively true (he has 
formally declared he's running).  So language can guarantee 
effect-similarity because it has the resources 
%-- sometimes albeit not always utilized %-- to formulate 
assertions that are relatively transparent, logically 
(of course, it can also produce the likes of 
`q.Sanders is a terrible presidential candidate` or 
`q.Sanders is an unelectable presidential candidate`/).  
So communality of side-effects depends on 
(sometimes, potential) logicality of language.  But 
conversely, it is hard to define the logicality of 
language without pointing out that logically 
transparent language (like `q.Sanders is running`/) 
evokes different kides of side effects than polarizing 
language (like `q.Sanders is unelectable`/).  
After all, the effect of some logically transparent 
enunciation is to introduce some propositional 
content into a public arena.  But communication 
only happens when the content thereby publicized 
is considered and maybe deemed true, which 
requires certain cognitive processes in a community of addressees.  
The logical content of language only `q.exists` insofar 
as logically reasonable utterances trigger 
logically guided cognitive operations.
`p`

`p.
Even if we accept that linguistic expressions can 
signify propositional content, this does not mean 
that a sentence is like a djinn which conjures 
propositions into material form.  Logical structures 
do not float around like snowflakes: if they exist, they 
do so as regulatory structures or specifications 
guiding the behavior or implementation of 
physically realized, synamically changable systems.  A 
computing platform can exemplify a Typed Lambda Calculus 
or Adjoint Tensor Logic or Modal Process Algebra by 
`i.implementing` such a system, but this 
does not mean a software artifact can `i.be` a 
logical system (or even can be a `i.token` of a 
logical system).  But the implementation of the 
system establishes an Ontological gap between the 
system as abstract Category and its physical realization.
`p`

`p.
Let's say, for sake of argument, that someone develops a `Cpp; 
Functional-Reactive Programming 
library (a not-too-ambitious enhancement of existing software) 
which fully realizes Jennifer Paykin's version of Tensor Algebra.  
It would be entirely possible for most (even expert) 
`Cpp; programmers to use that library without understanding or 
even being aware that their code was embodying some logical 
structure, separate and apart from the system 
of side-effects and function-calls that they orchestrate.  
Similarly, developers can create `Cpp; types that are functionally 
identical to Haskell monads, without being aware of 
the monadic logic thereby exmplified.  To say that 
logical systems are implemented in software is to say that 
the totality of all function-calls %-- both actually 
observed at runtime and theoretically possible for 
any run of a program %-- span an 
abstract space that is fully and adequately specified by 
the logic.  So we can say that a signal-slot connection 
causing some function-pointer to be followed represents the 
concrete manifestation of an abstract `q.temporal-monadic 
modality`/.  This means that the pattern of signal-slot 
connections does and will always conform to regulations 
that can be modeled via Adjoint Tensor Logic.  It also means 
that this coformance is a result of deliberate design 
%-- the logic exerts a normative effect on the 
software; it is not just a pattern retroactively discoverable 
in observed function-calls.  But 
what actually exists are the function-calls themselves, and 
there are many ways to comport to them without 
considering or being aware of the logic (we can enumerate 
function calls as a debugger trace, or study them in 
conventional `Cpp; terms without the added logical 
details).  The logic is manifest as a regulatory and emergent 
pattern and influence, but is also only one facet of 
the full ontological status of the vehicles (e.g., function-calls) 
wherein the logic is realized.
`p`

`p.
Insofar as Natural Language is logical, I would argue that its logic 
is manifest analogously: it is realized in the pattern 
of whatever cognitively corresponds to `q.function calls`/; 
e.g., the tendency of external (linguistic 
and otherwise) stimuli to trigger cognitive processes.  
`p`

`p.

`p`

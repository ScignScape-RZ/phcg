\subsection{Types, Sets, and Concepts}
\p{In formal/computational contexts, types can be defined as sets of both values and
\q{expectations} \cite{MathieuBouchard} (meaning assumptions which may be made about
all values covered by the type); alternatively, we can (perhaps better) consider types as
\i{spaces} of values.  Types' extensions have internal structure; there
can be \q{null} or \q{invalid} values, default-constructed values, and
so forth, which are \q{regions} of the conceptual space spanned or 
encompassing types.\footnote{Conceptual Space theory is outside the scope of this paper, but I'll note that 
it suggests a promising link between natural linguistics and formal/computational 
type theory, as suggested by computational or scientific expositions of 
the original Conceptual Space account developed by Peter \Gardenfors{}: 
cf. \cite{Zenker}, \cite{RaubalAdams} \cite{RaubalAdamsCSML}, 
\cite{Strle}.  Meanwhile, projects to develop formal models for 
Cognitive Grammar have also adopted Conceptual Space theory as an 
underlying semantics: \cite{KennethHolmqvist}, \cite{HolmqvistDiss}, 
\cite{MattSelway}, \cite{InteractingConceptualSpaces}.    
}
There is definitional interdependence
between types and functions: a function is defined in terms of the types it accepts as parameters and
returns \mdash{} rather than its entire set of possible inputs and outputs, which can
vary across computing environments.
\footnote{Moreover, expectations in a particular case
may be more precise than what is implied by the type itself \mdash{} it is erroneous
to assume that a proper type system will allow a correct \q{set of values} to
be stipulated for each point in a computation (the kind of contract enforced via
by documentation and unit testing).  So state-space in a given context may include many
\q{unreasonable} values, implying that within the overall space there is a \q{reasonable}
subspace, except that this subspace may not be crisply defined.
}  These are some reasons why in theoretical
Computer Science types are not \q{reduced} to underlying sets; instead, extensions
are sometimes complex spaces that model states of, or internal organization of comparisons
among, type instances.
}
\p{An obvious paradigm is organizing type-extensions around prototype/borderline
cases \mdash{} there are instances which are clear examples of types and
ones whose classification is dubious.  I contend, however, 
that common resemblance is not always a good marker
for types being well-conceived \mdash{} many useful concepts are common
precisely because they cover many cases, which makes defining
\q{prototypes} or \q{common properties} misleading.  
Also, sometimes the clearest
\q{representative} example of a type or concept is actually not a
\i{typical} example: a sample latter or model home is actually not (in
many cases) a real letter or home.  So resemblance-to-prototype is at
best one kind of \q{inner organization} of concepts' and types' spaces
of extension.  
}
\p{Sets, concepts, and types represent three different primordial thought-vehicles for
grounding notions of logic and meaning.  To organize systems around \i{sets} is
to forefront notions of inclusion, exclusion, extension, and intersection,
which are also formally essential to mathematical logic and undergird the
classical interdependence of sets, logic, and mathematics.
To organize systems around \i{concepts} is to forefront practical engagement
and how we mold conceptual profiles, as collections of ideas and pragmas,
to empirical situations.  To organize systems around \i{types} is to forefront
\q{functions} or transformations which operate on typed values, the interrelationships
between different types (like subtypes and inclusion \mdash{} a type can itself
encompass multiple values of other types), and the conceptual abstraction
of types themselves from the actual sets of values they may exhibit
in different environments.  Sets and types are
formal, abstract phenomena; whereas concepts are characterized by
gradations of applicability, and play flexible roles in thought and language.
The cognitive role of concepts can be discussed with some rigor, but there is a
complex interplay of cognitive schema and practical engagements which
would have to be meticulously sketched in many real-world scenarios, if
our goal were to translate conceptual reasoning to formal structures
on a case-by-case basis.  We can, however, consider in general
terms how type-theoretic semantics can capture conceptual structures
as part of the overall transitioning of thoughts to langauge.
}
\p{A concept does not merely package up a definition, like \q{restaurant} as
\q{a place to order food}; instead concepts link up with other concepts
as tools for describing and participating in situations.  Concepts are
associated with \q{scripts} of discourse and action, and find their
range of application through a variegated pragmatic scope.
We should be careful not to overlook these pragmatics, and
assume that conceptual structures can be simplistically
translated to formal models.
Cognitive Linguistics critiques
Set-Theoretic or Modal Logic reductionism (where a concept is just a set
of instances, or an extension across different possible worlds) \mdash{} George Lakoff and Mark Johnson,
prominently, argue for concepts' organization around
prototypes (\cite[p. 18]{LakoffJohnson}; \cite[p. 171, or p. \textit{xi}]{Johnson})
and embodied/enactive patterns of interaction (\cite[p. 90]{LakoffJohnson};
\cite[p. 208]{Johnson}).
Types, by contrast, at least in linguistic applications of type theory, are abstractions
defined in large part by quasi-functional notions of phrase struture.
Nevertheless, the \i{patterns} of how types may inter-relate
(mass-noun or count-noun, sentient or non-sentient, and so forth)
provide an infrastructure for conceptual understandings to be
encoded in language \mdash{} specifically, to be signaled by which typed
articulations conversants choose to use.  A concept like
\i{restaurant} enters language with a collection of understood
qualities (social phenomena, with some notion of spatial location and
being a \q{place}, etc.) that in turn can be marshaled by sets of
allowed or disallowed phrasal combinations, whose parameters
can be given type-like descriptions.  Types, in this sense,
are not direct expressions of concepts but vehicles for
introducing concepts into language.
}
\p{Concepts (and types also) are not cognitively the same as their
extension \mdash{} the concept \i{restaurant}, I believe, is distinct from
concepts like \i{all restaurants} or \i{the set of all restaurants}.
This is for several reasons.  First, concepts can be pairwise different
not only through their instances, but because they highlight different
sets of attributes or indicators.  The concepts \q{American President} and \q{Commander in Chief}
refer to the same person, but the latter foregrounds a military role.
Formal Concept Analysis considers \i{extensions} and \q{properties}
\mdash{} suggestive indicators that inhere in each
instance \mdash{} as jointly (and co-dependently) determinate: concepts
are formally a synthesis of instance-sets and property-sets \cite{YiyuYao},
\cite{Belohlavek}, \cite{Wille}.  Second,
in language, clear evidence for the contrast between \i{intension} and
\i{extension} comes from phrase structure: certain constructions specifically
refer to concept-extension, triggering a mental shift from thinking of the
concept as a schema or prototype to thinking of its extension (maybe in some context).
Compare:
\begin{sentenceList}\sentenceItem{} \label{itm:rhinor} Rhinos in that park are threatened by poachers.
\sentenceItem{} Young rhinos are threatened by poachers.
\end{sentenceList}
Both sentences focus a conceptual lens in greater detail than \i{rhino} in general, but
the second does so more intensionally, by adding an extra indicative criterion; while
the former does so extensionally, using a phrase-structure designed to operate on
and narrow our mental construal of \q{the set of all rhinos}, in the sense of
\i{existing} rhinos, their physical place and habitat, as opposed to
the \q{abstract} (or \q{universal}) type.  So there is a familiar semantic
pattern which mentally transitions from a lexical type to its extension and
then extension-narrowing \mdash{} an interpretation that, if accepted, clearly
shows a different mental role for concepts of concepts' \i{extension} than the
concepts themselves.\footnote{There is a type-theoretic correspondence between intension and
extension \mdash{} for a type \Tnoindex{} there is a corresponding \q{higher-order} type
of \i{sets} whose members are \Tnoindex{} 
(related constructions are the type of \i{ordered sequences} of \Tnoindex{};
unordered collections of \Tnoindex{} allowing repetition; and stacks, queues, and
deques \mdash{} double-ended queues \mdash{} as \Tnoindex{}-lists that can grow or shrink
at their beginning and/or end).  If we take this (higher-order)
type gloss seriously, the extension of a concept is not its \i{meaning}, but a
different, albeit interrelated concept.  Extension is not definition.
\i{Rhino} does not mean \i{all rhinos} (or \i{all possible rhinos}) \mdash{} though arguably
there are concepts \i{all rhinos} and \i{all restaurants} (etc.) along with the concepts
\i{rhino} and \i{restaurant}.
}  
}
\p{Concepts, in short, do not mentally signify sets, or
extensions, or sets-of-shared-properties.  Concepts, rather, are cognitive/dialogic tools.
Each concept-choice, as presentation device,
invites its own follow-up.  \i{Restaurant} or \i{house} have meaning not via
idealized mental pictures, or proto-schema, but via kinds of things
we do (eat, live), of conversations we have, of qualities we deem relevant.  Concepts do not
have to paint a complete picture, because we use them as part of ongoing situations
\mdash{} in language, ongoing conversations.  Narrow concepts \mdash{} which may best exemplify
\q{logical} models of concepts as resemblance-spaces or as rigid designators to
natural kinds \mdash{} have, in practice, fewer use-cases \i{because} there
are fewer chances for elaboration.  Very broad concepts, on the other hand, can have,
in context, too \i{little} built-in \i{a priori} detail.
(We say \q{restaurant} more often than \i{eatery}, and
more often than \i{diner}, \i{steakhouse}, or \i{taqueria}).  Concepts dynamically play
against each other, making \q{spaces} where different niches of meaning, including
levels of precision, converge as site for one or another.  Speakers need freedom to choose
finer or coarser grain, so concepts are profligate, but the most oft-used trend toward middle
ground, neither too narrow nor too broad.  \i{Restaurant} or \i{house} are useful because they are noncommittal, inviting more detail.
These dynamics govern the flow of inter-concept relations (disjointness, subtypes, partonymy, etc.).
}
\p{Concepts are not rigid formulae (like instance-sets or even attributes fixing when
they apply); they are mental gadgets to initiate and
guide dialog.  Importantly, this
contradicts the idea that concepts are unified around instances' similarity (to each other or
to some hypothetical prototype): concepts have avenues for contrasting
different examples, invoking a \q{script} for further elaboration, or for building temporary filters.  
In, say, 
\begin{sentenceList}\sentenceItem{} Let's find a restaurant that's family-friendly.
\end{sentenceList}
allowing such one-off narrowing is a feature
of the concept's flexibility.
}
\p{In essence: no less important, than acknowledged similarities across all instances, are well-rehearsed ways
\visavis{} each concept to narrow scope by marshaling lines of \i{contrast}, of \i{dissimilarity}.
A \i{house} is obviously different from a \i{skyscraper}
or a \i{tent}, and better resembles other houses; but there are also more nontrivial \i{comparisons}
between houses, than between a house and a skyscraper
or a tent.  Concepts are not only spaces of similarity, but of \i{meaningful kinds of differences}.
}
\p{To this account of conceptual breadth we can add the conceptual matrix spanned by
various (maybe overlapping) word-senses: to \i{fly}, for example, names
not a single concept, but a family of concepts all related to airborn
travel.  Variations highlight different features: the path of flight (\i{fly to Korea}, \i{fly over the mountain});
the means (\i{fly Korean air}, \i{that model flew during World War II});
the cause (\i{sent flying (by an explosion)}, \i{the bird flew away (after a loud noise)},
\i{leaves flying in the wind}).  Words allow different use-contexts
to the degree that their various \i{senses} offer an inventory of aspects for
highlighting by \i{morphosyntactic} convention.  Someone who says \i{I hate to fly} is not
heard to dislike hand-gliding or jumping off mountains.\footnote{People, unlike birds, do not fly \mdash{} so the verb, used intransitively
(not flying \i{to} somewhere in particular or \i{in} something in particular),
is understood to refer less to the physical motion and more to the socially
sanctioned phenomenon of buying a seat on a scheduled flight on an airplane. The construction
highlights the procedural and commercial dimension, not the physical mechanism and
spatial path.  But it does so \i{because} we know human flight is
unnatural: we can poetically describe how the sky is filled with flying leaves or birds,
but not \q{flying people}, even if we are nearby an airport.
}  Accordant variations
of cognitive construal (attending more to mode of action, or path, or motives, etc.),
which are elsewhere signaled by grammatic choices, are also spanned by a conceptual
space innate to a given word: senses are finer-grained meanings availing themselves to one construal or another.
}
\p{So situational construals can be signaled by word- and/or
syntactic form choice (locative, benefactive, direct and indirect
object constructions, and so forth).  Whereas conceptual organization
often functions by establishing classifications, and/or invoking
\q{scripts} of dialogic elaboration, cognitive structure tends to apply more
to our attention focusing on particular objects, sets of objects, events, or
aspects of events or situations.  
So the contrast between singular, mass-multiples, and count-multiples,
among nouns, depends on cognitive
construal of the behavior of the referent in question (if singular, its
propensity to act or be conceived as an integral whole; if multiple, its
disposition to either be divisible into discrete units, or not).
Or, events can be construed in terms of their causes
(their conditions at the outset), or their goals (their conditions at
the conclusion), or their means (their conditions in the interim).
Compare \i{attaching} something to a wall (means-focused) to
\i{hanging} something on a wall (ends-focused); \i{baking} a cake
(cause-focus: putting a cake in the oven with deliberate intent to cook it)
to \i{burning} a cake (accidentally overcooking it).\footnote{We can express
an intent to bake someone a cake, but not (well, maybe comedically) to
\i{burn} someone a cake (\q{burn}, at least in this context, implies
something not intended); however, we \i{can} say
\q{I burnt your cake}, while it is a little jarring to say
\q{I baked your cake} \mdash{} the possessive implies that some
specific cake is being talked about, and there is less apparent reason
to focus on one particular stage of its preparation (the baking) once
it is done.  I \i{will} bake a cake, in the future, uses
\q{bake} to mean also other steps in preparation (like \q{make}), while,
in the present, \q{the cake \i{is} baking} emphasizes more its
actual time in the oven.  I \i{baked your cake} seems to focus
(rather unexpectedly) on this specific stage even after it is completed,
whereas \i{I baked you a cake}, which is worded as if the recipient
did not know about the cake ahead of time, apparently uses \q{bake} in
the broader sense of \q{made}, not just \q{cooked in an oven}.
Words' senses mutate in relation to the kinds of situations where they are used
\mdash{} why else would \i{bake} mean \q{make}/\q{prepare} in the past or future tense but
\q{cook}/\q{heat} in the present?
}
These variations are not random assortments of polysemous words' senses:
they are, instead, rather predictably distributed according
to speakers' context-specific knowledge and motives.
}
\p{I claim therefore that \i{concepts} enter language complexly, influenced by
conceptual \i{spaces} and multi-dimensional semantic and syntactic selection-spaces.
Concepts are not simplistically \q{encoded} by types, as if for
each concept there is a linguistic or lexical type that just
disquotationally references it \mdash{} that the type \q{rhino} means the concept
\i{rhino} (\q{type} in the sense that type-theoretic semantics would model lexical
data according to type-theoretic rules, such as \i{rhino} as subtype of \i{animal} or
\i{living thing}).
Cognitive schema, at least in the terms I just laid out, select particularly
important gestalt principles (force dynamics, spatial frames, action-intention)
and isolate these from a conceptual matrix.  On this basis, we can argue that
these schemata form a precondition for concept-to-type association; or,
in the opposite logical direction, that language users' choices to employ
particular type articulations follow forth from their prelinguistic
cognizing of practical scenarios as this emerges out of collections
of concepts used to form a basic understanding of and self-positioning within them.
}
\p{In this sense I called types \q{vehicles} for concepts: not that types \i{denote}
concepts but that they (metaphorically) \q{carry} concepts into language.  
\q{Carrying} is enabled by types' semi-formal rule-bound
interactions with other types, which are positioned to capture concepts' variations and
relations with other concepts.
}
\p{To express a noun in the benefactive case, for example, which can be seen as attributing to
it a linguistic type consistent with being the target of a benefactive,
is to capture the concept in a type-theoretic gloss.
It tells us, I'm thinking about this thing in such a way that it
\i{can} take a benefactive (the type formalism attempting to capture
that \q{such a way}).
A concept-to-type \q{map}, as I just
suggested, is mediated (in experience and practical reasoning) by
cognitive organizations; when (social, embodied) enactions take
linguistic form, these organizing principles can be encoded in how
speakers apply morphosyntactic rules.  
}
\p{So the linguistic structures,
which I propose can be formally modeled by a kind of type theory, work
communicatively as carriers and thereby signifiers of cognitive
attitudes. The type is a vehicle for the concept because it takes part in constructions
which express conceptual details \mdash{} the details
don't emerge merely by virtue of the type itself.
I am not arguing for a neat concept-to-type correspondence; instead, a type system provides a
\q{formal substrate} that models (with some abstraction and simplification) how
properties of individual concepts translate
(via cognitive-schematic intermediaries) to their
manifestation in both semantics and syntax.
}
\p{Continuing with declention as a case study,
consider how an \q{ontology} of word senses 
can interrelate with the benefactive.
A noun as a benefactive target most often is a person or some other
sentient/animate being; an inanimate benefactive is most likely
something artificial and constructed (cf., \i{I got the car new tires}).
How readily hearers accept a sentence \mdash{} and the path they
take to construing its meaning so as to make it grammatically acceptable
\mdash{} involves interlocking morphological and type-related considerations;
in the current example, the mixture of benefactive case and which noun
\q{type} (assuming a basic division of nouns into e.g.
animate/constructed/natural) forces a broader or narrower
interpretation.  A benefactive with an \q{artifact} noun, for example,
almost forces the thing to be heard as somehow disrepaired:
\begin{sentenceList}\sentenceItem{} I got glue for your daughter.
\sentenceItem{} I got glue for your coffee mug.
\end{sentenceList}
We gather (in the second case) that the mug is broken \mdash{} but this is never spelled out
by any lexical choice; it is implied indirectly by using benefactive case.  
It is easy to design similar examples with other cases:
a locative construction rarely targets \q{sentient} nouns, so in
\begin{sentenceList}\sentenceItem{} We're going to Grandma!
\sentenceItem{} Let's go to him right now.
\sentenceItem{} Let's go to the lawyers.
\sentenceItem{} Let's go to the press.
\end{sentenceList}
we mentally substitute the person with the place where they live or work.
}
\p{Morphosyntactic
considerations are also at play: \i{to the lawyers} makes \q{go} sound more like \q{consult with},
partly because of the definite article (\i{the} lawyers implies conversants have some prior involvement
with specific lawyers or else are using the phrase metonymically, as in \q{go to court} or
\q{to the courts}, for
legal institutions generally; either reading draws attention away from literal spatial implications of
\q{go}). \i{Go to him} implies that \q{he} needs
some kind of help, because if the speaker just meant going to wherever he's at, she probably would
have said that instead.
}
\p{Similarly, the locative in \i{to the press} forces the mind to
reconfigure the landmark/trajector structure, where \i{going} is thought not as a literal
spatial path and \i{press} not a literal destination \mdash{} in other words, the phrase must be
read as a metaphor.  But the \q{metaphor} here is not \q{idiomatic} or removed from linguistic rules
(based on mental resemblance, not language structure); here it
clearly works off of formal language patterns: the landmark/trajector
relation is read abstracted from literal spatial movement because the locative is applied
to an expression (\i{the press}) which does not (simplistically) meet
the expected interpretation as \q{designation of place}.
}
\p{In short, there are two different levels of \i{granularity} where we 
can look for agreement requirements: a more fine-grained level where e.g. 
\i{locative} draws in a type-specification of a \i{place} or \i{location}; 
and a coarser level oriented toward Parts of Speech, and typologies 
of phrasal units.  On the finer scale, what linguistics can draw from type 
theory gravitates toward type-coercions, \q{dependent types}, and 
topics based on programming language type systems, like \q{monads} 
\mdash{} \cite{ZhaohuiLuo}, \cite{LuoSoloviev},
\cite{ChatzikyriakidisLuo},  
\cite{AsherPustejovsky}, 
\cite{BarkerShan}, \cite{ShanMonads}, \cite{ShanThesis}.  
On the coarser scale, on the other hand, 
analyses can focus on the interconnections between types and functions: 
most top-level linguistic types fit the formal model of 
(in computational contexts) \q{functional} types, associated with 
types of \q{inputs} and \q{outputs}.  For instance, 
assuming we have a primordial \i{noun} type and a \i{proposition} type 
(the type assigned to complete sentences), a \i{verb} is then at some 
abstract reading a \q{function} from nouns to propositions \mdash{} insofar 
as verbs produce propositions when combined with nouns.  Similarly 
an adjective maps nouns to other nouns (in a conceptual sense; noun-phrases, 
literally speaking); adverbs map verbs to other verbs, and so forth.              
}
\p{The proposition type (say, \q{\Prop{}}) provides a
type attribution for sentences, but also for sentence parts: \i{he is at school},
for example, presents a complete idea, either as its own sentence or part of a
larger one.  In the latter case, a \Prop{} phrase would typically be preceded with a
word like \i{that}; \i{syntactically}, \q{that} is essentially a 
connector, helping sentence-parts link with each other:
\begin{sentenceList}\sentenceItem{} I think he is at school.
\sentenceItem{} \label{itm:bt} I believe that he is at school.
\end{sentenceList}
Type-theoretically, however, we may want to assign types to every word, even those
\mdash{} like \i{that} in (\ref{itm:bt}) 
which seem auxiliary and lacking much or any semantic content of their own.
Arguably, \i{that} serves to \q{package} an assertion, encapsulating
a proposition as a presumed fact designated as
one idea, for the sake of making further comments, as if \q{making a noun} out
of it: \PropToN{}.  Perhaps our intuitions are more as if \i{that he is at school}
is also a proposition, maybe a subtly different kind, by analogy to how
questions and commands are also potentially \Prop{} variants.  Since \thatPhrases{} are \q{arguments} for verbs,
the choice then becomes whether it is useful to expand our type picture of verbs
so that they may act on propositions as well as nouns,
or rather type \q{encapsulated} propositions as just nouns
(maybe special kinds of nouns).
}
\p{In either case, \i{I know that ...} clearly involves a verb with subject and direct
object: so either \VisNNtoProp{} or \VisNProptoProp{}.  
Using \i{link grammar}, 
Consider the role of a \TS{}-link here:
specifically, \TS{} connects the verb to the assertorial direct object (most
directly, to \i{that}).\footnote{Link Grammar models parses via interword relations classified according to 
some four dozen recognized syntactic and semantic connectors; 
a complete parse yields a labeled \q{graph} of each sentence, similar to 
graphs derived from Depenency Grammars, with link-kinds notated via 
labels like \q{\TS{}} (the exact 
vocabulary of link kinds establishes specific grammars for specific 
natural languages) \mdash{} cf. \cite{SleatorTamperley};
\cite{Debusmann} 
\cite{DebusmannThesis}.  
\cite{DebusmannDuchierRossberg}, 
\cite{Nivre}.
Link Grammar is distinguished from Depenency Grammar in that the former 
does not directly model head/dependent relations within word-pairs, but 
it \i{does} develop a theory of individual words carrying incompleteness 
or expectations which define \q{compatibility} between words, allowing 
links to be formed; the link/dependency comparison is investigated in 
\cite{HongEisner}, ; and other writings compare both grammatic schools to 
more hierarchical phrase-structure grammars: 
\cite{KongRushSmith}, \cite{Schneider}, \cite{XiaPalmer}. 
}  The purely formal consideration is ensuring that
types are consistent: either the \TS{} target is \Prop{}, 
with the verb type modified accordingly; or the \TS{} target is a noun,
though here it is fair to narrow scope.  For this particular kind of
link, the target must express a proposition: either typed directly as
such or typed as, say, a noun \q{packaging} a proposition, which would then
be a higher-order type relation (just as \q{redness} is a noun \q{packaging}
an adjective, or \q{running} is an adjective packaging a verb).  In other words,
it is difficult to state the type restrictions on the link-pair without employing
more complex or higher-order type formations.
}
\p{On the other hand, this is
another example of the fuzzy boundary between syntax and semantics: given a sentence
which seems to link a verb calling for a belief or assertion (like \q{know},
\q{think}, \q{suggest}, \q{to be glad}) to something that is not proposition-like, is such a
configuration ungrammatical, or just hard to understand?  Clearly, the
\i{semantic} norms around verbs like \q{know} is that their \i{subject}
has some quality of sentience (or can be meaningfully attributed
belief-states, even if speakers know not to take it literally: \q{The function
doesn't know that this number will never be zero}); and their \i{object} should
be somehow propositional.  But applying type theory (or type theory in conjunction
with Dependency Grammar) leaves open various analytic preferences: these
requirements can be presented as rigid grammatic rules or as \q{post-parsing}
semantic regulations.  How to model the qualities of sentience (or at least of having
propositional attitudes broadly conceived), for the noun, and of propositionality,
for the direct object, are again at the discretion
of the analysis (subtypes, quality-associations, or etc.) \mdash{} Figure ~\ref{fig:Iknow} shows one potential,
rather simplified unpacking of the sentence; from this structure details
can be added perhaps as extra syntax constraints or perhaps more as cues
to interpretation.\input{figure.tex}  If these
requirements are seen as more syntactic, so qualities are incorporated into
data like Part of Speech (say, a noun designating something with propositional attitudes
being a subtype of of a generic \N{} type), then we are more likely to analyze
violations as simply incorrect (recall \q{The tree wants to run away from the dog}
\mdash{} ungrammatical or just somehow \q{exotic}?).
Some examples suggest less incorrectness as clever or poetic usage \mdash{} so a
richer analysis may recognize expressions as type- and link-wise acceptable, but
showing incongruities (which is not the same as impropriety)
at a more fine-grained type level.  That \i{to want} takes a subject
\i{associated} with sentience does not force type annotations to inscribe this
in grammatic or lexical laws; instead, these associations can be
introduced as potential \q{side effects}, \i{triggering} re-associations
such as forcing hearers to ascribe sentience to something (like a tree) where
such ascription is not instinctive.  The type effect in this case lies more
at the conceptual level, the language-user sifting conceptual
backgrounds to find a configuration proper to the type requirements (in what
sense can a tree \q{want} something?).  In this \q{tree} case we probably
appeal to concepts of \q{as if}: if the tree \i{were} sentient, it
would be nervous of the dog sniffing around \mdash{} a humorous way of calling
attention to the dog's actions (obliquely maybe alluding to people's background
knowledge that dogs sometimes do things, like pee, in inconvenient
places, from humans' perspectives).
}
\p{In brief, it is certainly possible \mdash{} though by no means mandatory \mdash{} to model
type requirements with greater flexibility at a provisional grammatical layer,
and then narrow in on subtypes or extra accumulations of qualifications on
type-instances in a transition from grammar to semantics.  Perhaps cognitive
schema occupy an intermediary role: progressing from basic recognition of
grammaticality, through cognitive schema, to conceptual framing, with type
machinery capturing some of the thought-processes at each \q{step}
(not that such \q{steps} are necessarily in a temporal sequence).  The basic
verb-subject-direct object articulation sets up an underlying cognitive
attitude (represented by a basic type-framing of verb, noun, and proposition,
like the \VisNNtoProp{} signature).  Cognitive ascriptions fill this out
by adding detail to the broader-hewed typing, associating sentience with the
subject and propositionality with the object (sub- or higher-order typing
modeling this stage).  And how the actual lexical choices fit these cognitive
expectations \mdash{} I call them cognitive because they are intrinsically tied
to structurational schema in the type, morphology, and word-order givens
in the encountered language \mdash{} compels conversants to dip into background
beliefs, finding concepts for the signified meanings that hew to the
intermediary cognitive manipulations (finding ways to conceptualize the
subject as sentient, for example).  This also has a potential type model,
perhaps as forcing a type conversion from a lexical element which does
not ordinarily fit the required framing (such as giving inanimate things
some fashion of sentience).  Type theory
can give a window onto unfolding intellection at these multiple stages,
although we need not conclude that the mind subconsciously doing this thinking
mimics a computer that churns through type transformations mechanically and exactly.
}
\p{I envision the unfolding that I have just sketched out as something Phenomenological
\mdash{} it arises from a unified and subjective consciousness, one marked by
embodied personal identity and social situation.  If there are structural stases
that can be found in this temporality of experience, these are not constitutive
of conscious reality but a mesh of rationality that supports it, like the veins in
a leaf.  Stuctural configurations can be lifted from language insofar as it is a
conscious, formally governed activity, and lifted from the ambient situations which
lend language context and meaning intents.  So any analytic emphasis on
structural fixpoints threaded through the lived temporality of consciousness is an
abstraction, but one that is deliberate and necessary if we want to make scientific
or in any other manner disputatable claims about how language and congition works.
In that spirit, then, I will try to condense the three \q{layers} of unfolding
understanding, which as I have sketched them are posited in the metaphysical order
of temporal experience \mdash{} \q{unfolding} in likely overlapping, blending ways
\mdash{} I will \q{read into} them a more static and logically stacked meta-structure.
Where I have sketched three layers or stages of unfolding language understanding,
I will transition to proposing three \q{tiers} of language organization, in particular
three levels where type-theoretic models can be applied.
}

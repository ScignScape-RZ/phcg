\section{Phenomenology, AI, and Holism}
\p{This situation is not irrelevant to either linguistics or to Cognitive
Phenomenology.  In Computational Linguistics,
for example, linguistic IR models seem
to be valued based on their utility in AI-driven
Natural Language Processing.  This presents a disciplinary
bifurcation, where potential computational models
are \i{either} connoted rather informally as part of
a thoretical investigation among linguists
(or philosophers of language, etc.), \i{or}
concretely implemented, in some kind of software package,
but then measured as components in a Natural Language Processing
system: assessed on the basis of how the system overall
approximates human language understanding via artifical means.
Another genre of formal models,
such as the type- or monadic theories I have alluded to here,
may also have potential software incarnations but
tend to be developed instead in a mathematical
style, effectively \q{programming} in the abstract
space of theorems and syllogisms rather than actual
compuers.  Each of these methodologies skirt
around the potential intermediary tie:
concrete computational systems that are
designed as exemplifications of semantic, grammmatical,
or pragmatic theories, presented as hands-on
software to anchor theoretical discussion but also intended
as tools to advance the human study of language, rather
than as steps toward synthetic avatars.
}
\p{At the same time, there is another side to the story: software
implementations offer a focal center for research, something
tangible that scholars can experiment and collaborate on.
The AI story provides a target goal; it helps developers understand
the local, technical code they are working on by
connecting it to a larger system.
Whatever philosophical objection one may have to AI
initiatives, we should recognize the value of
expanding academic and institutional practice beyond
just writing and reading research papers.  Insofar as
part of one's scholarly modus operandi can include
writing computer code, and studying code
repositories developed by others, we can benefit from a
hands-on, even trial-and-error kind of experimentation.
}
\p{In effect: software which can be given concrete tasks \mdash{} if it
does \i{this} properly (whatever \i{this} is),
then there is some larger thoretical point that
is demonstrated \mdash{} and then, incrementally, evolves
to realize those tasks, provides a distinct form
of intellectual engagement.  We get \i{that} to work, then
\i{that}, then fix \i{that}.  This kind of
\q{code-and-fix} cycle is quicker than conventional
research, especially in the humanities, where the
routines of authorship and publication and conferences can
feel like they are unfolding in slow motion.
}
\p{Perhaps for this reason, some of the most interesting
cognitive models hacve come from
computational and academic environemnts informed by
ambitious \q{Artificial General Intelligence}
programmes, like Carnegie Melon University's
OpenCog, and the \q{lmnTal} project at Waseda University
in Tokyo.  These projects both employ
formal-semantically expressive, hypergraph-oriented
data systems that embody both the structural
and procedural dimensions of computer systems \mdash{}
manifesting theories of both the execution
of computational processes and the representation of
formalized information.  These are important
models even outside the Artificial General Intelligence
ideology.
}
\p{In fact, these are models which in linguistics
and phenomenology may deserve more attention
than Artificial General Intelligence \i{qua}
philosophy.  But we should not discredit the
role that Artificial General Intelligence may
provide as a kind of intellectual compass helping
scholars and engineers reason through the
intrestitial machinery which may in fact be
more real than the philosophical vision, but
also less effective as theoretical \i{vie ferrate}.
Metaphors can triangulate research
whereas analogies guide transfers of theories
or methods between fields \mdash{} i.e., analogies are
more trustworthy landmarks than metaphors
for surveying the envisioned future of a science
\mdash{} but metaphors can still be intuitive guides;
maybe AI and Artificial General Intelligence can
stabilize into our overall science and
philosophy as a modest but suggestive metaphor.
}
\p{}
\p{}

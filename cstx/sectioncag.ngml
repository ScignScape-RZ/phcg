
`section.Channel-Algebraic Grammar`
`p.
This section will briefly introduce what I call 
`q.Channel Algebra` and how it can lead to a 
theory (and practice, in a sense) of formal 
and natural-language grammar.  Channel Algebra 
is discussed in greater detail in `cite<Neustein>;.  
It's fairly divergent from other formalizations 
in computer science, though loosely decended from 
Process Algebras and from the `q.sigma calculus`/, 
which is a formal model of Object-Oriented 
programming `cite<AbadiCardelli>;.  Channel Algebra 
may also be seen as distantly related to Santanu 
Paul's `q.Source Code Algebra` `cite<SantanuPaul>; 
and to a network of discussions %-- not necessarily 
coalesced into technical publications 
%-- about how to unify Object Oriented 
and Functional Programming.  There are many 
interesting analyses presented by scientists like 
Bartosz Milewski, on web forums such as 
Milewski's blog (the address is his full name as a 
dot-com domain).  In general, 
though, I am developing Channel Algebra 
in an `q.experimental` manner, using a concrete software 
implementation in lieu of a technical or 
mathematical axiomatic description.
`p`

`p.
In the present context I want to focus on Channel Algebra as a 
potential theory in linguistic %-- particularly 
Cognitive Grammar %-- but initially I'll describe 
the underlying theory in a more computational manner.  
A lot of the Channel Algebra formalization carries 
between formal and natural languages.
`p`

`p.
A key notion in Channel Algebra is `i.procedures`/.  As in 
Part 1, we can think of procedures as either cognitive 
processes or as functions implemented in a software 
system, although for exposition the latter interpretation 
is simpler.  So, assume we have a computing environment 
where many functions are available to be 
called %-- in effect, a bundle of software libraries 
each exposing some collection of function-implementations.  
For reasons I'll cover momentarily, I'll call thse 
`i.ambient procedures`/.
`p`

`p.
At one level, Channel Algebra is conceived as an alternative 
to data-sharing paradigms like the Semantic Web; so, one 
kind of analysis is concerned with cases where some body 
of information (which can be called a `i.data set`/) 
needs to be transferred between two different 
computing environments.  Channel Algebra takes the 
view that data does not have intrinsic semantics outside 
the computational environments where it is used.  
As I argued in the context of Searle's `q.Chinese Room`/, 
our identification that a software system represents facts 
%-- like someone's full name (the example I used over several 
paragraphs in the earlier discussion) %-- depends on the 
software possessing capabilities to display the 
information (usually visually).  In other words, 
among the total of all procedures that can be performed by 
the system, only a small set of procdures are involved in 
user-interactions where semantic intentions like 
`q.this piece of data represents someone's full name` are 
relevant.
`p`

`p.
As a consequence, when sharing data that includes 
information like `i.full-name`/, we should not assume 
that the raw data, in its semantic interpretation, 
actually `q.means` `i.full-name`/, or some kind  
of propositional assertion about full names.  For 
example, a graph-edge in a Semantic Web resource 
intended to model the proposition `q.This person has full 
name Jane Doe` should not be seen as `q.meaning` anything about 
full names.  Instead, it represents some computational 
artifact which `i.becomes` an asserion of that fact 
when a procedure is eventually calld which converts 
the full name to a (usually visual) representation 
which a human user would recognize as a view 
on a full name (and hence on the proposition).
`p`

`p.
In sum, the Semantic Web (or any data sharing 
network) only `i.has` a semantics because software 
connected by the network has requisite procedures to 
make data-views that people can understand.  Data does 
not have semantics (or at least not 
human-conceptual semantics); `i.views` do.  
This is consistent with an Interface Theory: most procedures 
manipulating Semantic Web data are part of an 
interface connecting networked data sources to the 
handful of procedures which create views for human users.  
Within the local structure of this interface, data does not 
have a `q.human` semantics; instead, it must be passed around 
between proceurs before eventually 
reaching human-interaction procedures where 
(what we would call) the `q.real` 
procedures come into play. 
`p`

`p.
When data is shared btween localities, then, the procedures 
that will receive and manipulate this data are logicallly 
prior to the data itself and constrain when data-sharing is 
possible.  Without the proper network of procedures, 
the data can never be transformed into the views 
where non-local semantics are relevant.  
This motivates my choosing the term `q.`i.ambient` procedures`/, 
because a certain collection of procedures must be in place 
on the receiver end of a data-sharing event.  This also implies 
that one important role of data modeling is to indicate 
which procures a potential receiver needs to have 
available %-- i.e., needs to implement %-- to qualify as a 
capable recipient of data conforming to the model.  
Data models should describe what procedural 
capabilities must be afforded by software libraries in 
order for the human-level, conceptual semantics of 
the data can actually emerge from humans' 
interactions with the system.  
`p`

`p.
Analogous to Ontologies as data model specifications 
for the Semantic Web, I'll use the term `q.Ambient-Procedural 
Ontologies` to express the paradigm that implememting data-sharing 
protocols involves crafting software libraries around 
procedural requirements.  This has two implications for 
how we theorize software systems.  First, we need to characterize 
procedures in a manner that expresses the proceural 
capabilities that a system offers, or must have to satisfy a 
data-sharing protocol.  Second, we can assume that 
whenever data is sent, received, manipulated, or visualized, 
there is a collection of procedures available in the system 
which enact these computational processes.  
`p`

`p.
On this basis, then, I will develop a Type Theory that operationalizes 
this intuition about `q.Ambient Procedural Ontologies`/.  
The main outlines of this type theory are first that procdures 
have types; and second that procedures are `q.ambient` or 
logically prior to (or at least equiprimordial with) the 
type system itself.  This is not a mathematical type system 
where every underlying type (like Natural Numbers) and 
every operation (like arithmetic operators) have to be 
mathematically described in the theory.  
Instead, we can always take certain types and procedures as 
`q.primitive` or (at least in their inner workings) 
external to the type theory.  For any type system `tSys;, 
whose structure is regulated by a type theory we ijyend 
to prsent or assess, we can say that `tSys` is built 
around a `i.kernal` `kErn; or `q.primitive` 
types and functions.
`p`

`p.

`p`

